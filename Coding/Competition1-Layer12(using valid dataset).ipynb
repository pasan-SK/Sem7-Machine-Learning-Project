{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np          # For mathematical calculations\n",
    "import matplotlib.pyplot as plt  # For plotting graphs\n",
    "# import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "train_csv_file_path = \"D:\\\\ACA semester 7\\\\CS4622 - Machine Learning\\\\ML-Project\\\\Data\\\\layer12\\\\train.csv\"\n",
    "valid_csv_file_path = \"D:\\\\ACA semester 7\\\\CS4622 - Machine Learning\\\\ML-Project\\\\Data\\\\layer12\\\\valid.csv\"\n",
    "test_csv_file_path = \"D:\\\\ACA semester 7\\\\CS4622 - Machine Learning\\\\ML-Project\\\\Data\\\\layer12\\\\test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031138</td>\n",
       "      <td>0.079892</td>\n",
       "      <td>0.157382</td>\n",
       "      <td>-0.014636</td>\n",
       "      <td>-0.051778</td>\n",
       "      <td>-0.021332</td>\n",
       "      <td>-0.073593</td>\n",
       "      <td>-0.005386</td>\n",
       "      <td>-0.212557</td>\n",
       "      <td>0.099683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085248</td>\n",
       "      <td>-0.096007</td>\n",
       "      <td>-0.000766</td>\n",
       "      <td>0.021399</td>\n",
       "      <td>-0.041432</td>\n",
       "      <td>0.094806</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.113040</td>\n",
       "      <td>0.175731</td>\n",
       "      <td>0.217741</td>\n",
       "      <td>-0.196254</td>\n",
       "      <td>-0.010129</td>\n",
       "      <td>-0.030586</td>\n",
       "      <td>0.067114</td>\n",
       "      <td>-0.072412</td>\n",
       "      <td>-0.239192</td>\n",
       "      <td>0.104741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090283</td>\n",
       "      <td>-0.053885</td>\n",
       "      <td>-0.010967</td>\n",
       "      <td>0.062209</td>\n",
       "      <td>-0.122958</td>\n",
       "      <td>0.192949</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048570</td>\n",
       "      <td>0.091281</td>\n",
       "      <td>0.160776</td>\n",
       "      <td>-0.150937</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.044117</td>\n",
       "      <td>-0.050092</td>\n",
       "      <td>-0.045661</td>\n",
       "      <td>-0.155332</td>\n",
       "      <td>0.117206</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021524</td>\n",
       "      <td>-0.008411</td>\n",
       "      <td>-0.006248</td>\n",
       "      <td>0.031468</td>\n",
       "      <td>-0.056915</td>\n",
       "      <td>0.154731</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.039212</td>\n",
       "      <td>0.118388</td>\n",
       "      <td>0.173831</td>\n",
       "      <td>-0.096659</td>\n",
       "      <td>-0.008702</td>\n",
       "      <td>0.061298</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>-0.003277</td>\n",
       "      <td>-0.065046</td>\n",
       "      <td>0.095480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071936</td>\n",
       "      <td>-0.023120</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>-0.121892</td>\n",
       "      <td>0.072796</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056019</td>\n",
       "      <td>0.170639</td>\n",
       "      <td>0.157917</td>\n",
       "      <td>-0.228605</td>\n",
       "      <td>-0.065965</td>\n",
       "      <td>-0.088732</td>\n",
       "      <td>-0.082243</td>\n",
       "      <td>-0.080568</td>\n",
       "      <td>-0.341500</td>\n",
       "      <td>0.142430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155621</td>\n",
       "      <td>-0.079447</td>\n",
       "      <td>0.015316</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>-0.151966</td>\n",
       "      <td>0.169634</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.031138   0.079892   0.157382  -0.014636  -0.051778  -0.021332   \n",
       "1   0.113040   0.175731   0.217741  -0.196254  -0.010129  -0.030586   \n",
       "2   0.048570   0.091281   0.160776  -0.150937   0.020115   0.044117   \n",
       "3   0.039212   0.118388   0.173831  -0.096659  -0.008702   0.061298   \n",
       "4   0.056019   0.170639   0.157917  -0.228605  -0.065965  -0.088732   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_763  feature_764  \\\n",
       "0  -0.073593  -0.005386  -0.212557    0.099683  ...    -0.085248    -0.096007   \n",
       "1   0.067114  -0.072412  -0.239192    0.104741  ...    -0.090283    -0.053885   \n",
       "2  -0.050092  -0.045661  -0.155332    0.117206  ...    -0.021524    -0.008411   \n",
       "3   0.008974  -0.003277  -0.065046    0.095480  ...    -0.071936    -0.023120   \n",
       "4  -0.082243  -0.080568  -0.341500    0.142430  ...    -0.155621    -0.079447   \n",
       "\n",
       "   feature_765  feature_766  feature_767  feature_768  label_1  label_2  \\\n",
       "0    -0.000766     0.021399    -0.041432     0.094806       45      NaN   \n",
       "1    -0.010967     0.062209    -0.122958     0.192949       45      NaN   \n",
       "2    -0.006248     0.031468    -0.056915     0.154731       45      NaN   \n",
       "3    -0.007812     0.057600    -0.121892     0.072796       45      NaN   \n",
       "4     0.015316     0.127726    -0.151966     0.169634       45      NaN   \n",
       "\n",
       "   label_3  label_4  \n",
       "0        1        6  \n",
       "1        1        6  \n",
       "2        1        6  \n",
       "3        1        6  \n",
       "4        1        6  \n",
       "\n",
       "[5 rows x 772 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_csv_file_path)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1      float64\n",
       "feature_2      float64\n",
       "feature_3      float64\n",
       "feature_4      float64\n",
       "feature_5      float64\n",
       "                ...   \n",
       "feature_768    float64\n",
       "label_1          int64\n",
       "label_2        float64\n",
       "label_3          int64\n",
       "label_4          int64\n",
       "Length: 772, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get type of each column\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming Labels\n",
    "\n",
    "*   Since the labels are in 'label_1', 'label_2' ... format, I will be renaming them to 'speaker_ID', 'speaker_age', ... format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.rename(columns={'label_1': 'speaker_ID', 'label_2': 'speaker_age', 'label_3': 'speaker_gender', 'label_4': 'speaker_accent'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "      <th>speaker_ID</th>\n",
       "      <th>speaker_age</th>\n",
       "      <th>speaker_gender</th>\n",
       "      <th>speaker_accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28520.000000</td>\n",
       "      <td>28520.000000</td>\n",
       "      <td>28520.000000</td>\n",
       "      <td>28520.000000</td>\n",
       "      <td>28520.000000</td>\n",
       "      <td>28520.000000</td>\n",
       "      <td>28520.000000</td>\n",
       "      <td>28520.000000</td>\n",
       "      <td>28520.000000</td>\n",
       "      <td>28520.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>28520.000000</td>\n",
       "      <td>28520.000000</td>\n",
       "      <td>28520.000000</td>\n",
       "      <td>28520.000000</td>\n",
       "      <td>28520.000000</td>\n",
       "      <td>28520.000000</td>\n",
       "      <td>28520.000000</td>\n",
       "      <td>28040.000000</td>\n",
       "      <td>28520.000000</td>\n",
       "      <td>28520.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.042487</td>\n",
       "      <td>0.068749</td>\n",
       "      <td>0.145547</td>\n",
       "      <td>-0.070646</td>\n",
       "      <td>-0.013539</td>\n",
       "      <td>0.003395</td>\n",
       "      <td>-0.041282</td>\n",
       "      <td>-0.028283</td>\n",
       "      <td>-0.106602</td>\n",
       "      <td>0.053686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022102</td>\n",
       "      <td>-0.044743</td>\n",
       "      <td>-0.004380</td>\n",
       "      <td>0.049072</td>\n",
       "      <td>-0.028722</td>\n",
       "      <td>0.075717</td>\n",
       "      <td>30.498843</td>\n",
       "      <td>27.975107</td>\n",
       "      <td>0.799299</td>\n",
       "      <td>5.997125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.048918</td>\n",
       "      <td>0.046354</td>\n",
       "      <td>0.065332</td>\n",
       "      <td>0.046671</td>\n",
       "      <td>0.027635</td>\n",
       "      <td>0.031248</td>\n",
       "      <td>0.026479</td>\n",
       "      <td>0.029632</td>\n",
       "      <td>0.070775</td>\n",
       "      <td>0.030945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053250</td>\n",
       "      <td>0.031361</td>\n",
       "      <td>0.025829</td>\n",
       "      <td>0.050536</td>\n",
       "      <td>0.032622</td>\n",
       "      <td>0.044879</td>\n",
       "      <td>17.328389</td>\n",
       "      <td>5.735913</td>\n",
       "      <td>0.400532</td>\n",
       "      <td>2.375567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.079594</td>\n",
       "      <td>-0.062608</td>\n",
       "      <td>-0.048545</td>\n",
       "      <td>-0.307243</td>\n",
       "      <td>-0.178347</td>\n",
       "      <td>-0.194771</td>\n",
       "      <td>-0.197551</td>\n",
       "      <td>-0.304828</td>\n",
       "      <td>-0.421257</td>\n",
       "      <td>-0.049723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253255</td>\n",
       "      <td>-0.264549</td>\n",
       "      <td>-0.137827</td>\n",
       "      <td>-0.117697</td>\n",
       "      <td>-0.302399</td>\n",
       "      <td>-0.090777</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.009979</td>\n",
       "      <td>0.037225</td>\n",
       "      <td>0.100677</td>\n",
       "      <td>-0.088834</td>\n",
       "      <td>-0.027810</td>\n",
       "      <td>-0.010617</td>\n",
       "      <td>-0.056682</td>\n",
       "      <td>-0.044344</td>\n",
       "      <td>-0.135110</td>\n",
       "      <td>0.033236</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042332</td>\n",
       "      <td>-0.056918</td>\n",
       "      <td>-0.018848</td>\n",
       "      <td>0.012599</td>\n",
       "      <td>-0.045226</td>\n",
       "      <td>0.045309</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.024445</td>\n",
       "      <td>0.056119</td>\n",
       "      <td>0.123554</td>\n",
       "      <td>-0.057386</td>\n",
       "      <td>-0.011423</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>-0.041501</td>\n",
       "      <td>-0.025805</td>\n",
       "      <td>-0.080715</td>\n",
       "      <td>0.045567</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007960</td>\n",
       "      <td>-0.037407</td>\n",
       "      <td>-0.004701</td>\n",
       "      <td>0.033121</td>\n",
       "      <td>-0.022919</td>\n",
       "      <td>0.064875</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.058410</td>\n",
       "      <td>0.086358</td>\n",
       "      <td>0.173234</td>\n",
       "      <td>-0.039661</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.021250</td>\n",
       "      <td>-0.026559</td>\n",
       "      <td>-0.009324</td>\n",
       "      <td>-0.057873</td>\n",
       "      <td>0.065670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012116</td>\n",
       "      <td>-0.024179</td>\n",
       "      <td>0.010218</td>\n",
       "      <td>0.072599</td>\n",
       "      <td>-0.006335</td>\n",
       "      <td>0.097642</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.274146</td>\n",
       "      <td>0.332288</td>\n",
       "      <td>0.454182</td>\n",
       "      <td>0.059362</td>\n",
       "      <td>0.196950</td>\n",
       "      <td>0.213127</td>\n",
       "      <td>0.124194</td>\n",
       "      <td>0.105714</td>\n",
       "      <td>0.192121</td>\n",
       "      <td>0.252320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209455</td>\n",
       "      <td>0.054555</td>\n",
       "      <td>0.215375</td>\n",
       "      <td>0.376414</td>\n",
       "      <td>0.125857</td>\n",
       "      <td>0.416291</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature_1     feature_2     feature_3     feature_4     feature_5  \\\n",
       "count  28520.000000  28520.000000  28520.000000  28520.000000  28520.000000   \n",
       "mean       0.042487      0.068749      0.145547     -0.070646     -0.013539   \n",
       "std        0.048918      0.046354      0.065332      0.046671      0.027635   \n",
       "min       -0.079594     -0.062608     -0.048545     -0.307243     -0.178347   \n",
       "25%        0.009979      0.037225      0.100677     -0.088834     -0.027810   \n",
       "50%        0.024445      0.056119      0.123554     -0.057386     -0.011423   \n",
       "75%        0.058410      0.086358      0.173234     -0.039661      0.001544   \n",
       "max        0.274146      0.332288      0.454182      0.059362      0.196950   \n",
       "\n",
       "          feature_6     feature_7     feature_8     feature_9    feature_10  \\\n",
       "count  28520.000000  28520.000000  28520.000000  28520.000000  28520.000000   \n",
       "mean       0.003395     -0.041282     -0.028283     -0.106602      0.053686   \n",
       "std        0.031248      0.026479      0.029632      0.070775      0.030945   \n",
       "min       -0.194771     -0.197551     -0.304828     -0.421257     -0.049723   \n",
       "25%       -0.010617     -0.056682     -0.044344     -0.135110      0.033236   \n",
       "50%        0.006173     -0.041501     -0.025805     -0.080715      0.045567   \n",
       "75%        0.021250     -0.026559     -0.009324     -0.057873      0.065670   \n",
       "max        0.213127      0.124194      0.105714      0.192121      0.252320   \n",
       "\n",
       "       ...   feature_763   feature_764   feature_765   feature_766  \\\n",
       "count  ...  28520.000000  28520.000000  28520.000000  28520.000000   \n",
       "mean   ...     -0.022102     -0.044743     -0.004380      0.049072   \n",
       "std    ...      0.053250      0.031361      0.025829      0.050536   \n",
       "min    ...     -0.253255     -0.264549     -0.137827     -0.117697   \n",
       "25%    ...     -0.042332     -0.056918     -0.018848      0.012599   \n",
       "50%    ...     -0.007960     -0.037407     -0.004701      0.033121   \n",
       "75%    ...      0.012116     -0.024179      0.010218      0.072599   \n",
       "max    ...      0.209455      0.054555      0.215375      0.376414   \n",
       "\n",
       "        feature_767   feature_768    speaker_ID   speaker_age  speaker_gender  \\\n",
       "count  28520.000000  28520.000000  28520.000000  28040.000000    28520.000000   \n",
       "mean      -0.028722      0.075717     30.498843     27.975107        0.799299   \n",
       "std        0.032622      0.044879     17.328389      5.735913        0.400532   \n",
       "min       -0.302399     -0.090777      1.000000     22.000000        0.000000   \n",
       "25%       -0.045226      0.045309     15.000000     25.000000        1.000000   \n",
       "50%       -0.022919      0.064875     30.000000     27.000000        1.000000   \n",
       "75%       -0.006335      0.097642     46.000000     30.000000        1.000000   \n",
       "max        0.125857      0.416291     60.000000     61.000000        1.000000   \n",
       "\n",
       "       speaker_accent  \n",
       "count    28520.000000  \n",
       "mean         5.997125  \n",
       "std          2.375567  \n",
       "min          0.000000  \n",
       "25%          6.000000  \n",
       "50%          6.000000  \n",
       "75%          6.000000  \n",
       "max         13.000000  \n",
       "\n",
       "[8 rows x 772 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for null/NaN values in all columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1         False\n",
       "feature_2         False\n",
       "feature_3         False\n",
       "feature_4         False\n",
       "feature_5         False\n",
       "                  ...  \n",
       "feature_768       False\n",
       "speaker_ID        False\n",
       "speaker_age        True\n",
       "speaker_gender    False\n",
       "speaker_accent    False\n",
       "Length: 772, dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().any()\n",
    "\n",
    "# Based on below output we can see that there are missing values in the speaker_age column of the dataset.\n",
    "# Let's now check whether that is the only column with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1           0\n",
       "feature_2           0\n",
       "feature_3           0\n",
       "feature_4           0\n",
       "feature_5           0\n",
       "                 ... \n",
       "feature_768         0\n",
       "speaker_ID          0\n",
       "speaker_age       480\n",
       "speaker_gender      0\n",
       "speaker_accent      0\n",
       "Length: 772, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum().sum()\n",
    "\n",
    "# Based on the above and below outputs, we can see that there are 480 missing values 'only' in the speaker_age column. No missing values in other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset shape: (28520, 772)\n",
      "null values row count:  480\n",
      "null values row count percentage:  1.6830294530154277\n"
     ]
    }
   ],
   "source": [
    "print(\"train dataset shape:\", train_df.shape)\n",
    "print(\"null values row count: \", train_df.isnull().sum().sum())\n",
    "print(\"null values row count percentage: \", (train_df.isnull().sum().sum() / train_df.shape[0]) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.0    4762\n",
       "25.0    2849\n",
       "27.0    2846\n",
       "23.0    2842\n",
       "31.0    2385\n",
       "24.0    1906\n",
       "28.0    1899\n",
       "30.0    1894\n",
       "22.0    1432\n",
       "29.0    1424\n",
       "33.0     945\n",
       "36.0     481\n",
       "35.0     480\n",
       "34.0     478\n",
       "32.0     476\n",
       "41.0     474\n",
       "61.0     467\n",
       "Name: speaker_age, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's now check the distribution of the speaker_age column.\n",
    "train_df.speaker_age.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Null values (Replace with Mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  27.975106990014265\n",
      "mean (rounded): 28\n"
     ]
    }
   ],
   "source": [
    "# Let's get the mean of the speaker_age column.\n",
    "speaker_age_mean = train_df.speaker_age.mean()\n",
    "print(\"mean: \", speaker_age_mean)\n",
    "\n",
    "# round it to nearest int\n",
    "speaker_age_mean = round(speaker_age_mean)\n",
    "print(\"mean (rounded):\", speaker_age_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now fill the missing values with the mean value.\n",
    "train_df.speaker_age.fillna(speaker_age_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.speaker_age.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking each Label distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.0    4762\n",
       "25.0    2849\n",
       "27.0    2846\n",
       "23.0    2842\n",
       "31.0    2385\n",
       "28.0    2379\n",
       "24.0    1906\n",
       "30.0    1894\n",
       "22.0    1432\n",
       "29.0    1424\n",
       "33.0     945\n",
       "36.0     481\n",
       "35.0     480\n",
       "34.0     478\n",
       "32.0     476\n",
       "41.0     474\n",
       "61.0     467\n",
       "Name: speaker_age, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's now check the distribution of the speaker_age column.\n",
    "train_df.speaker_age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number os unique values in speaker age column\n",
    "train_df.speaker_age.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.speaker_age.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a slight class imbalance issue based on above outputs. As a solution we can use RandomForrestClassifier with class_weight='balanced' parameter.\n",
    "\n",
    "# Note; hpt: forest_params = [{'max_depth': list(range(10, 15)), 'max_features': list(range(0,14))}]\n",
    "\n",
    "# use averaged F1 score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    485\n",
       "35    484\n",
       "26    483\n",
       "60    482\n",
       "24    482\n",
       "25    481\n",
       "59    481\n",
       "10    481\n",
       "54    481\n",
       "45    480\n",
       "41    480\n",
       "9     480\n",
       "2     479\n",
       "42    479\n",
       "47    479\n",
       "6     479\n",
       "56    479\n",
       "34    478\n",
       "52    478\n",
       "3     478\n",
       "14    478\n",
       "33    478\n",
       "43    477\n",
       "1     477\n",
       "13    477\n",
       "20    477\n",
       "23    477\n",
       "30    476\n",
       "51    476\n",
       "32    476\n",
       "53    476\n",
       "22    476\n",
       "38    476\n",
       "49    476\n",
       "55    475\n",
       "28    474\n",
       "8     474\n",
       "40    474\n",
       "48    474\n",
       "21    474\n",
       "4     474\n",
       "39    473\n",
       "17    473\n",
       "7     473\n",
       "15    472\n",
       "58    472\n",
       "5     471\n",
       "27    471\n",
       "31    470\n",
       "19    469\n",
       "11    469\n",
       "46    469\n",
       "29    469\n",
       "36    468\n",
       "16    468\n",
       "50    467\n",
       "37    467\n",
       "44    467\n",
       "57    466\n",
       "18    465\n",
       "Name: speaker_ID, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's now check the distribution of the speaker_ID column.\n",
    "train_df.speaker_ID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get num of unique values in speaker_ID column.\n",
    "train_df.speaker_ID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.speaker_ID.value_counts().plot.bar()\n",
    "\n",
    "# There is no significant class imbalance issue based on above outputs for the Speaker_ID column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    22796\n",
       "0     5724\n",
       "Name: speaker_gender, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's now check the distribution of the speaker_age column.\n",
    "train_df.speaker_gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.speaker_gender.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.speaker_gender.value_counts().plot.bar()\n",
    "\n",
    "# There is a significant class imbalance issue in speaker_gender column. As a solution we can use RandomForrestClassifier with class_weight='balanced' parameter.\n",
    "# Also when splitting the dataset, I will use the stratisfied sampling technique.\n",
    "\n",
    "# Note; hpt: forest_params = [{'max_depth': list(range(10, 15)), 'max_features': list(range(0,14))}]\n",
    "\n",
    "# NOte; print classification report | use averaged/macro F1\n",
    "\n",
    "# # Define the steps in your pipeline\n",
    "# steps = [\n",
    "#     ('scaler', StandardScaler()),  # Standardize the features\n",
    "#     ('oversampler', SMOTE(random_state=42)),  # Apply SMOTE for oversampling\n",
    "#     ('pca', PCA(n_components=0.95)),  # Apply PCA for dimensionality reduction\n",
    "#     ('xgb', XGBClassifier(scale_pos_weight=np.sqrt(np.sum(y == 0) / np.sum(y == 1))))  # XGBoost Classifier\n",
    "# ]\n",
    "\n",
    "# The parameter scale_pos_weight is used in XGBoost to address class imbalance. It's an important hyperparameter to consider when working with imbalanced datasets. The specific value provided (np.sqrt(np.sum(y == 0) / np.sum(y == 1))) is a common heuristic used for setting scale_pos_weight, but it should be chosen based on the characteristics of your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker accent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     19938\n",
       "2      1449\n",
       "0       955\n",
       "12      954\n",
       "7       938\n",
       "13      482\n",
       "1       481\n",
       "11      480\n",
       "10      480\n",
       "3       479\n",
       "5       478\n",
       "9       472\n",
       "4       469\n",
       "8       465\n",
       "Name: speaker_accent, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's now check the distribution of the speaker_age column.\n",
    "train_df.speaker_accent.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.speaker_accent.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGhCAYAAACDNqXeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1qklEQVR4nO3de3QV5b3/8c9OIBeEHa65HWIIYAUkXNUYLwg1TcAc2lRO5Q5qgOIJKsRyUwoBuhoOLKR0gbA8inhaVKBVFFAgBIEiASQYbgqVm8HCDiqSzUUTIM/vD3+Zwz4QJJrrw/u11qyVmee7Z74zBvcns2dmu4wxRgAAAJbxq+4GAAAAKgMhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgpTrV3UB1Kikp0YkTJ9SgQQO5XK7qbgcAANwAY4zOnj2ryMhI+fmVfb7mpg45J06cUFRUVHW3AQAAfoTjx4+refPmZY7f1CGnQYMGkr4/SG63u5q7AQAAN8Lr9SoqKsp5Hy/LTR1ySj+icrvdhBwAAGqZH7rUhAuPAQCAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVyhVyMjMzddddd6lBgwYKDQ1VSkqKDh486FPz3XffKS0tTU2aNFH9+vXVp08fFRQU+NTk5+crOTlZ9erVU2hoqMaOHatLly751GzcuFFdunRRYGCgWrdurcWLF1/Vz/z589WiRQsFBQUpLi5OO3bsKM/uAAAAi5Ur5GzatElpaWnatm2bsrKydPHiRSUmJur8+fNOzZgxY7Ry5UotX75cmzZt0okTJ/TII48445cvX1ZycrKKi4u1detWvfbaa1q8eLEmT57s1Bw9elTJycnq0aOH8vLyNHr0aA0bNkxr1651apYuXar09HRNmTJFu3btUseOHZWUlKRTp079lOMBAABsYX6CU6dOGUlm06ZNxhhjzpw5Y+rWrWuWL1/u1Hz66adGksnJyTHGGPPee+8ZPz8/4/F4nJoFCxYYt9ttioqKjDHGjBs3ztxxxx0+2+rbt69JSkpy5u+++26TlpbmzF++fNlERkaazMzMG+6/sLDQSDKFhYXl2GsAAFCdbvT9+yddk1NYWChJaty4sSQpNzdXFy9eVEJCglPTpk0b3XrrrcrJyZEk5eTkKDY2VmFhYU5NUlKSvF6v9u/f79RcuY7SmtJ1FBcXKzc316fGz89PCQkJTs21FBUVyev1+kwAAMBOPzrklJSUaPTo0brvvvvUvn17SZLH41FAQIAaNmzoUxsWFiaPx+PUXBlwSsdLx65X4/V69e233+qrr77S5cuXr1lTuo5ryczMVEhIiDNFRUWVf8cBAECt8KNDTlpamvbt26c333yzIvupVBMnTlRhYaEzHT9+vLpbAgAAlaTOj3nRqFGjtGrVKm3evFnNmzd3loeHh6u4uFhnzpzxOZtTUFCg8PBwp+b/3gVVevfVlTX/946sgoICud1uBQcHy9/fX/7+/tesKV3HtQQGBiowMLBc+9piwupy1Zfl2IzkClkPAAC4MeU6k2OM0ahRo/T2229rw4YNiomJ8Rnv2rWr6tatq+zsbGfZwYMHlZ+fr/j4eElSfHy89u7d63MXVFZWltxut9q1a+fUXLmO0prSdQQEBKhr164+NSUlJcrOznZqAADAza1cZ3LS0tL0+uuv65133lGDBg2c619CQkIUHByskJAQpaamKj09XY0bN5bb7dZTTz2l+Ph43XPPPZKkxMREtWvXToMHD9bMmTPl8Xg0adIkpaWlOWdZRo4cqXnz5mncuHF64okntGHDBi1btkyrV//vWZX09HQNHTpUd955p+6++2796U9/0vnz5/X4449X1LEBAAC1WLlCzoIFCyRJ3bt391n+6quv6rHHHpMkzZkzR35+furTp4+KioqUlJSkF1980an19/fXqlWr9OSTTyo+Pl633HKLhg4dqmnTpjk1MTExWr16tcaMGaO5c+eqefPmevnll5WUlOTU9O3bV19++aUmT54sj8ejTp06ac2aNVddjAwAAG5OLmOMqe4mqovX61VISIgKCwvldruvWcM1OQAA1Cw38v4t8d1VAADAUoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBK5Q45mzdvVu/evRUZGSmXy6UVK1b4jLtcrmtOs2bNcmpatGhx1fiMGTN81rNnzx498MADCgoKUlRUlGbOnHlVL8uXL1ebNm0UFBSk2NhYvffee+XdHQAAYKlyh5zz58+rY8eOmj9//jXHT5486TMtWrRILpdLffr08ambNm2aT91TTz3ljHm9XiUmJio6Olq5ubmaNWuWMjIy9NJLLzk1W7duVf/+/ZWamqqPP/5YKSkpSklJ0b59+8q7SwAAwEJ1yvuCXr16qVevXmWOh4eH+8y/88476tGjh1q2bOmzvEGDBlfVllqyZImKi4u1aNEiBQQE6I477lBeXp5eeOEFjRgxQpI0d+5c9ezZU2PHjpUkTZ8+XVlZWZo3b54WLlxY3t0CAACWqdRrcgoKCrR69WqlpqZeNTZjxgw1adJEnTt31qxZs3Tp0iVnLCcnR926dVNAQICzLCkpSQcPHtQ333zj1CQkJPisMykpSTk5OZW0NwAAoDYp95mc8njttdfUoEEDPfLIIz7Ln376aXXp0kWNGzfW1q1bNXHiRJ08eVIvvPCCJMnj8SgmJsbnNWFhYc5Yo0aN5PF4nGVX1ng8njL7KSoqUlFRkTPv9Xp/0v4BAICaq1JDzqJFizRw4EAFBQX5LE9PT3d+7tChgwICAvTb3/5WmZmZCgwMrLR+MjMzNXXq1EpbPwAAqDkq7eOqf/zjHzp48KCGDRv2g7VxcXG6dOmSjh07Jun763oKCgp8akrnS6/jKaumrOt8JGnixIkqLCx0puPHj5dnlwAAQC1SaSHnlVdeUdeuXdWxY8cfrM3Ly5Ofn59CQ0MlSfHx8dq8ebMuXrzo1GRlZen2229Xo0aNnJrs7Gyf9WRlZSk+Pr7M7QQGBsrtdvtMAADATuUOOefOnVNeXp7y8vIkSUePHlVeXp7y8/OdGq/Xq+XLl1/zLE5OTo7+9Kc/affu3Tpy5IiWLFmiMWPGaNCgQU6AGTBggAICApSamqr9+/dr6dKlmjt3rs/HXM8884zWrFmj2bNn68CBA8rIyNDOnTs1atSo8u4SAACwULmvydm5c6d69OjhzJcGj6FDh2rx4sWSpDfffFPGGPXv3/+q1wcGBurNN99URkaGioqKFBMTozFjxvgEmJCQEK1bt05paWnq2rWrmjZtqsmTJzu3j0vSvffeq9dff12TJk3Sc889p9tuu00rVqxQ+/bty7tLAADAQi5jjKnuJqqL1+tVSEiICgsLy/zoqsWE1RWyrWMzkitkPQAA3Oxu5P1b4rurAACApQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVyh1yNm/erN69eysyMlIul0srVqzwGX/sscfkcrl8pp49e/rUnD59WgMHDpTb7VbDhg2Vmpqqc+fO+dTs2bNHDzzwgIKCghQVFaWZM2de1cvy5cvVpk0bBQUFKTY2Vu+99155dwcAAFiq3CHn/Pnz6tixo+bPn19mTc+ePXXy5ElneuONN3zGBw4cqP379ysrK0urVq3S5s2bNWLECGfc6/UqMTFR0dHRys3N1axZs5SRkaGXXnrJqdm6dav69++v1NRUffzxx0pJSVFKSor27dtX3l0CAAAWchljzI9+scult99+WykpKc6yxx57TGfOnLnqDE+pTz/9VO3atdNHH32kO++8U5K0Zs0aPfzww/riiy8UGRmpBQsW6Pnnn5fH41FAQIAkacKECVqxYoUOHDggSerbt6/Onz+vVatWOeu+55571KlTJy1cuPCG+vd6vQoJCVFhYaHcbvc1a1pMWH1D6/ohx2YkV8h6AAC42d3I+7dUSdfkbNy4UaGhobr99tv15JNP6uuvv3bGcnJy1LBhQyfgSFJCQoL8/Py0fft2p6Zbt25OwJGkpKQkHTx4UN98841Tk5CQ4LPdpKQk5eTkVMYuAQCAWqZORa+wZ8+eeuSRRxQTE6PDhw/rueeeU69evZSTkyN/f395PB6Fhob6NlGnjho3biyPxyNJ8ng8iomJ8akJCwtzxho1aiSPx+Msu7KmdB3XUlRUpKKiImfe6/X+pH0FAAA1V4WHnH79+jk/x8bGqkOHDmrVqpU2btyohx56qKI3Vy6ZmZmaOnVqtfYAAACqRqXfQt6yZUs1bdpUhw4dkiSFh4fr1KlTPjWXLl3S6dOnFR4e7tQUFBT41JTO/1BN6fi1TJw4UYWFhc50/Pjxn7ZzAACgxqr0kPPFF1/o66+/VkREhCQpPj5eZ86cUW5urlOzYcMGlZSUKC4uzqnZvHmzLl686NRkZWXp9ttvV6NGjZya7Oxsn21lZWUpPj6+zF4CAwPldrt9JgAAYKdyh5xz584pLy9PeXl5kqSjR48qLy9P+fn5OnfunMaOHatt27bp2LFjys7O1q9+9Su1bt1aSUlJkqS2bduqZ8+eGj58uHbs2KEPP/xQo0aNUr9+/RQZGSlJGjBggAICApSamqr9+/dr6dKlmjt3rtLT050+nnnmGa1Zs0azZ8/WgQMHlJGRoZ07d2rUqFEVcFgAAEBtV+6Qs3PnTnXu3FmdO3eWJKWnp6tz586aPHmy/P39tWfPHv3yl7/Uz372M6Wmpqpr1676xz/+ocDAQGcdS5YsUZs2bfTQQw/p4Ycf1v333+/zDJyQkBCtW7dOR48eVdeuXfXss89q8uTJPs/Suffee/X666/rpZdeUseOHfW3v/1NK1asUPv27X/K8QAAAJb4Sc/Jqe14Tg4AALVPtT4nBwAAoLoRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAK5U75GzevFm9e/dWZGSkXC6XVqxY4YxdvHhR48ePV2xsrG655RZFRkZqyJAhOnHihM86WrRoIZfL5TPNmDHDp2bPnj164IEHFBQUpKioKM2cOfOqXpYvX642bdooKChIsbGxeu+998q7OwAAwFLlDjnnz59Xx44dNX/+/KvGLly4oF27dun3v/+9du3apbfeeksHDx7UL3/5y6tqp02bppMnTzrTU0895Yx5vV4lJiYqOjpaubm5mjVrljIyMvTSSy85NVu3blX//v2Vmpqqjz/+WCkpKUpJSdG+ffvKu0sAAMBCdcr7gl69eqlXr17XHAsJCVFWVpbPsnnz5unuu+9Wfn6+br31Vmd5gwYNFB4efs31LFmyRMXFxVq0aJECAgJ0xx13KC8vTy+88IJGjBghSZo7d6569uypsWPHSpKmT5+urKwszZs3TwsXLizvbgEAAMtU+jU5hYWFcrlcatiwoc/yGTNmqEmTJurcubNmzZqlS5cuOWM5OTnq1q2bAgICnGVJSUk6ePCgvvnmG6cmISHBZ51JSUnKycmpvJ0BAAC1RrnP5JTHd999p/Hjx6t///5yu93O8qefflpdunRR48aNtXXrVk2cOFEnT57UCy+8IEnyeDyKiYnxWVdYWJgz1qhRI3k8HmfZlTUej6fMfoqKilRUVOTMe73en7yPAACgZqq0kHPx4kU9+uijMsZowYIFPmPp6enOzx06dFBAQIB++9vfKjMzU4GBgZXVkjIzMzV16tRKWz8AAKg5KuXjqtKA8/nnnysrK8vnLM61xMXF6dKlSzp27JgkKTw8XAUFBT41pfOl1/GUVVPWdT6SNHHiRBUWFjrT8ePHy7trAACglqjwkFMacD777DOtX79eTZo0+cHX5OXlyc/PT6GhoZKk+Ph4bd68WRcvXnRqsrKydPvtt6tRo0ZOTXZ2ts96srKyFB8fX+Z2AgMD5Xa7fSYAAGCncn9cde7cOR06dMiZP3r0qPLy8tS4cWNFREToP/7jP7Rr1y6tWrVKly9fdq6Rady4sQICApSTk6Pt27erR48eatCggXJycjRmzBgNGjTICTADBgzQ1KlTlZqaqvHjx2vfvn2aO3eu5syZ42z3mWee0YMPPqjZs2crOTlZb775pnbu3OlzmzkAALh5uYwxpjwv2Lhxo3r06HHV8qFDhyojI+OqC4ZLffDBB+revbt27dql//zP/9SBAwdUVFSkmJgYDR48WOnp6T7X4+zZs0dpaWn66KOP1LRpUz311FMaP368zzqXL1+uSZMm6dixY7rttts0c+ZMPfzwwze8L16vVyEhISosLCzzrE6LCatveH3Xc2xGcoWsBwCAm92NvH9LPyLk2ISQAwBA7XOjIYfvrgIAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAK5U75GzevFm9e/dWZGSkXC6XVqxY4TNujNHkyZMVERGh4OBgJSQk6LPPPvOpOX36tAYOHCi3262GDRsqNTVV586d86nZs2ePHnjgAQUFBSkqKkozZ868qpfly5erTZs2CgoKUmxsrN57773y7g4AALBUuUPO+fPn1bFjR82fP/+a4zNnztSf//xnLVy4UNu3b9ctt9yipKQkfffdd07NwIEDtX//fmVlZWnVqlXavHmzRowY4Yx7vV4lJiYqOjpaubm5mjVrljIyMvTSSy85NVu3blX//v2Vmpqqjz/+WCkpKUpJSdG+ffvKu0sAAMBCLmOM+dEvdrn09ttvKyUlRdL3Z3EiIyP17LPP6ne/+50kqbCwUGFhYVq8eLH69eunTz/9VO3atdNHH32kO++8U5K0Zs0aPfzww/riiy8UGRmpBQsW6Pnnn5fH41FAQIAkacKECVqxYoUOHDggSerbt6/Onz+vVatWOf3cc8896tSpkxYuXHhD/Xu9XoWEhKiwsFBut/uaNS0mrP5Rx+b/OjYjuULWAwDAze5G3r+lCr4m5+jRo/J4PEpISHCWhYSEKC4uTjk5OZKknJwcNWzY0Ak4kpSQkCA/Pz9t377dqenWrZsTcCQpKSlJBw8e1DfffOPUXLmd0prS7VxLUVGRvF6vzwQAAOxUoSHH4/FIksLCwnyWh4WFOWMej0ehoaE+43Xq1FHjxo19aq61jiu3UVZN6fi1ZGZmKiQkxJmioqLKu4sAAKCWuKnurpo4caIKCwud6fjx49XdEgAAqCQVGnLCw8MlSQUFBT7LCwoKnLHw8HCdOnXKZ/zSpUs6ffq0T8211nHlNsqqKR2/lsDAQLndbp8JAADYqUJDTkxMjMLDw5Wdne0s83q92r59u+Lj4yVJ8fHxOnPmjHJzc52aDRs2qKSkRHFxcU7N5s2bdfHiRacmKytLt99+uxo1auTUXLmd0prS7QAAgJtbuUPOuXPnlJeXp7y8PEnfX2ycl5en/Px8uVwujR49Wn/4wx/07rvvau/evRoyZIgiIyOdO7Datm2rnj17avjw4dqxY4c+/PBDjRo1Sv369VNkZKQkacCAAQoICFBqaqr279+vpUuXau7cuUpPT3f6eOaZZ7RmzRrNnj1bBw4cUEZGhnbu3KlRo0b99KMCAABqvTrlfcHOnTvVo0cPZ740eAwdOlSLFy/WuHHjdP78eY0YMUJnzpzR/fffrzVr1igoKMh5zZIlSzRq1Cg99NBD8vPzU58+ffTnP//ZGQ8JCdG6deuUlpamrl27qmnTppo8ebLPs3Tuvfdevf7665o0aZKee+453XbbbVqxYoXat2//ow4EAACwy096Tk5tx3NyAACofarlOTkAAAA1BSEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALBShYecFi1ayOVyXTWlpaVJkrp3737V2MiRI33WkZ+fr+TkZNWrV0+hoaEaO3asLl265FOzceNGdenSRYGBgWrdurUWL15c0bsCAABqsToVvcKPPvpIly9fdub37dunX/ziF/rNb37jLBs+fLimTZvmzNerV8/5+fLly0pOTlZ4eLi2bt2qkydPasiQIapbt67++Mc/SpKOHj2q5ORkjRw5UkuWLFF2draGDRumiIgIJSUlVfQuAQCAWqjCQ06zZs185mfMmKFWrVrpwQcfdJbVq1dP4eHh13z9unXr9Mknn2j9+vUKCwtTp06dNH36dI0fP14ZGRkKCAjQwoULFRMTo9mzZ0uS2rZtqy1btmjOnDmEHAAAIKmSr8kpLi7WX//6Vz3xxBNyuVzO8iVLlqhp06Zq3769Jk6cqAsXLjhjOTk5io2NVVhYmLMsKSlJXq9X+/fvd2oSEhJ8tpWUlKScnJzr9lNUVCSv1+szAQAAO1X4mZwrrVixQmfOnNFjjz3mLBswYICio6MVGRmpPXv2aPz48Tp48KDeeustSZLH4/EJOJKceY/Hc90ar9erb7/9VsHBwdfsJzMzU1OnTq2o3QMAADVYpYacV155Rb169VJkZKSzbMSIEc7PsbGxioiI0EMPPaTDhw+rVatWldmOJk6cqPT0dGfe6/UqKiqqUrcJAACqR6WFnM8//1zr1693ztCUJS4uTpJ06NAhtWrVSuHh4dqxY4dPTUFBgSQ51/GEh4c7y66scbvdZZ7FkaTAwEAFBgaWe18AAEDtU2nX5Lz66qsKDQ1VcnLydevy8vIkSREREZKk+Ph47d27V6dOnXJqsrKy5Ha71a5dO6cmOzvbZz1ZWVmKj4+vwD0AAAC1WaWEnJKSEr366qsaOnSo6tT535NFhw8f1vTp05Wbm6tjx47p3Xff1ZAhQ9StWzd16NBBkpSYmKh27dpp8ODB2r17t9auXatJkyYpLS3NOQszcuRIHTlyROPGjdOBAwf04osvatmyZRozZkxl7A4AAKiFKiXkrF+/Xvn5+XriiSd8lgcEBGj9+vVKTExUmzZt9Oyzz6pPnz5auXKlU+Pv769Vq1bJ399f8fHxGjRokIYMGeLzXJ2YmBitXr1aWVlZ6tixo2bPnq2XX36Z28cBAIDDZYwx1d1EdfF6vQoJCVFhYaHcbvc1a1pMWF0h2zo24/of2wEAgBtzI+/fEt9dBQAALEXIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsVOEhJyMjQy6Xy2dq06aNM/7dd98pLS1NTZo0Uf369dWnTx8VFBT4rCM/P1/JycmqV6+eQkNDNXbsWF26dMmnZuPGjerSpYsCAwPVunVrLV68uKJ3BQAA1GKVcibnjjvu0MmTJ51py5YtztiYMWO0cuVKLV++XJs2bdKJEyf0yCOPOOOXL19WcnKyiouLtXXrVr322mtavHixJk+e7NQcPXpUycnJ6tGjh/Ly8jR69GgNGzZMa9eurYzdAQAAtVCdSllpnToKDw+/anlhYaFeeeUVvf766/r5z38uSXr11VfVtm1bbdu2Tffcc4/WrVunTz75ROvXr1dYWJg6deqk6dOna/z48crIyFBAQIAWLlyomJgYzZ49W5LUtm1bbdmyRXPmzFFSUlJl7BIAAKhlKuVMzmeffabIyEi1bNlSAwcOVH5+viQpNzdXFy9eVEJCglPbpk0b3XrrrcrJyZEk5eTkKDY2VmFhYU5NUlKSvF6v9u/f79RcuY7SmtJ1lKWoqEher9dnAgAAdqrwkBMXF6fFixdrzZo1WrBggY4ePaoHHnhAZ8+elcfjUUBAgBo2bOjzmrCwMHk8HkmSx+PxCTil46Vj16vxer369ttvy+wtMzNTISEhzhQVFfVTdxcAANRQFf5xVa9evZyfO3TooLi4OEVHR2vZsmUKDg6u6M2Vy8SJE5Wenu7Me71egg4AAJaq9FvIGzZsqJ/97Gc6dOiQwsPDVVxcrDNnzvjUFBQUONfwhIeHX3W3Ven8D9W43e7rBqnAwEC53W6fCQAA2KnSQ865c+d0+PBhRUREqGvXrqpbt66ys7Od8YMHDyo/P1/x8fGSpPj4eO3du1enTp1yarKysuR2u9WuXTun5sp1lNaUrgMAAKDCQ87vfvc7bdq0SceOHdPWrVv161//Wv7+/urfv79CQkKUmpqq9PR0ffDBB8rNzdXjjz+u+Ph43XPPPZKkxMREtWvXToMHD9bu3bu1du1aTZo0SWlpaQoMDJQkjRw5UkeOHNG4ceN04MABvfjii1q2bJnGjBlT0bsDAABqqQq/JueLL75Q//799fXXX6tZs2a6//77tW3bNjVr1kySNGfOHPn5+alPnz4qKipSUlKSXnzxRef1/v7+WrVqlZ588knFx8frlltu0dChQzVt2jSnJiYmRqtXr9aYMWM0d+5cNW/eXC+//DK3jwMAAIfLGGOqu4nq4vV6FRISosLCwjKvz2kxYXWFbOvYjOQKWQ8AADe7G3n/lvjuKgAAYClCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgpQoPOZmZmbrrrrvUoEEDhYaGKiUlRQcPHvSp6d69u1wul880cuRIn5r8/HwlJyerXr16Cg0N1dixY3Xp0iWfmo0bN6pLly4KDAxU69attXjx4oreHQAAUEtVeMjZtGmT0tLStG3bNmVlZenixYtKTEzU+fPnfeqGDx+ukydPOtPMmTOdscuXLys5OVnFxcXaunWrXnvtNS1evFiTJ092ao4ePark5GT16NFDeXl5Gj16tIYNG6a1a9dW9C4BAIBaqE5Fr3DNmjU+84sXL1ZoaKhyc3PVrVs3Z3m9evUUHh5+zXWsW7dOn3zyidavX6+wsDB16tRJ06dP1/jx45WRkaGAgAAtXLhQMTExmj17tiSpbdu22rJli+bMmaOkpKSK3i0AAFDLVPo1OYWFhZKkxo0b+yxfsmSJmjZtqvbt22vixIm6cOGCM5aTk6PY2FiFhYU5y5KSkuT1erV//36nJiEhwWedSUlJysnJKbOXoqIieb1enwkAANipws/kXKmkpESjR4/Wfffdp/bt2zvLBwwYoOjoaEVGRmrPnj0aP368Dh48qLfeekuS5PF4fAKOJGfe4/Fct8br9erbb79VcHDwVf1kZmZq6tSpFbqPAACgZqrUkJOWlqZ9+/Zpy5YtPstHjBjh/BwbG6uIiAg99NBDOnz4sFq1alVp/UycOFHp6enOvNfrVVRUVKVtDwAAVJ9K+7hq1KhRWrVqlT744AM1b978urVxcXGSpEOHDkmSwsPDVVBQ4FNTOl96HU9ZNW63+5pncSQpMDBQbrfbZwIAAHaq8JBjjNGoUaP09ttva8OGDYqJifnB1+Tl5UmSIiIiJEnx8fHau3evTp065dRkZWXJ7XarXbt2Tk12drbPerKyshQfH19BewIAAGqzCg85aWlp+utf/6rXX39dDRo0kMfjkcfj0bfffitJOnz4sKZPn67c3FwdO3ZM7777roYMGaJu3bqpQ4cOkqTExES1a9dOgwcP1u7du7V27VpNmjRJaWlpCgwMlCSNHDlSR44c0bhx43TgwAG9+OKLWrZsmcaMGVPRuwQAAGqhCg85CxYsUGFhobp3766IiAhnWrp0qSQpICBA69evV2Jiotq0aaNnn31Wffr00cqVK511+Pv7a9WqVfL391d8fLwGDRqkIUOGaNq0aU5NTEyMVq9eraysLHXs2FGzZ8/Wyy+/zO3jAABAkuQyxpjqbqK6eL1ehYSEqLCwsMzrc1pMWF0h2zo2I7lC1gMAwM3uRt6/Jb67CgAAWIqQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAAr1anuBlA+fGEoAAA3hjM5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVeBggfrSa9mDCiuinJvUi8dBGAPgpOJMDAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASz8kBbgI8Q+jaalIvUs3qpyb1IvE7fD0cm7JxJgcAAFiJkAMAAKxEyAEAAFaq9SFn/vz5atGihYKCghQXF6cdO3ZUd0sAAKAGqNUhZ+nSpUpPT9eUKVO0a9cudezYUUlJSTp16lR1twYAAKpZrQ45L7zwgoYPH67HH39c7dq108KFC1WvXj0tWrSoulsDAADVrNaGnOLiYuXm5iohIcFZ5ufnp4SEBOXk5FRjZwAAoCaotc/J+eqrr3T58mWFhYX5LA8LC9OBAweu+ZqioiIVFRU584WFhZIkr9db5nZKii5UQLfX30Z51KR+alIvUsX0U5N6kWpWPzWpF4nf4evh2FxbTepFqln91KRepB/up3TcGHP9FZla6l//+peRZLZu3eqzfOzYsebuu+++5mumTJliJDExMTExMTFZMB0/fvy6WaHWnslp2rSp/P39VVBQ4LO8oKBA4eHh13zNxIkTlZ6e7syXlJTo9OnTatKkiVwu14/qw+v1KioqSsePH5fb7f5R66hINamfmtRLTeuHXmpHPzWpl5rWT03qpab1Qy+V348xRmfPnlVkZOR162ptyAkICFDXrl2VnZ2tlJQUSd+HluzsbI0aNeqarwkMDFRgYKDPsoYNG1ZIP263u0b8ApWqSf3UpF6kmtUPvZStJvVTk3qRalY/NakXqWb1Qy9lq4h+QkJCfrCm1oYcSUpPT9fQoUN155136u6779af/vQnnT9/Xo8//nh1twYAAKpZrQ45ffv21ZdffqnJkyfL4/GoU6dOWrNmzVUXIwMAgJtPrQ45kjRq1KgyP56qCoGBgZoyZcpVH4NVl5rUT03qRapZ/dBL2WpSPzWpF6lm9VOTepFqVj/0Uraq7sdlzA/dfwUAAFD71NqHAQIAAFwPIQcAAFiJkAMAAKxEyAEAwGI386W3tf7uKtQcX331lRYtWqScnBx5PB5JUnh4uO6991499thjatasWTV3CAAV7+TJk1qwYIG2bNmikydPys/PTy1btlRKSooee+wx+fv7V2t/gYGB2r17t9q2bVutfVQH7q4qh127dqlRo0aKiYmRJP3lL3/RwoULlZ+fr+joaI0aNUr9+vWr0p6+/fZb5ebmqnHjxmrXrp3P2Hfffadly5ZpyJAhld7HRx99pKSkJNWrV08JCQnOs4oKCgqUnZ2tCxcuaO3atbrzzjsrvZea5qmnntKjjz6qBx54oLpbqXWOHz+uKVOmaNGiRdXdyk3v008/1bZt2xQfH682bdrowIEDmjt3roqKijRo0CD9/Oc/r7bezp8/r2XLlunQoUOKiIhQ//791aRJkyrZ9s6dO5WQkKDWrVsrODhYOTk5GjBggIqLi7V27Vq1a9dOa9asUYMGDSq9lyu/tuhKc+fO1aBBg5xj8sILL1R6L6XmzZunHTt26OGHH1a/fv30l7/8RZmZmSopKdEjjzyiadOmqU6dSjzfUgHflXnT6NChg8nKyjLGGPPf//3fJjg42Dz99NNmwYIFZvTo0aZ+/frmlVdeqbJ+Dh48aKKjo43L5TJ+fn6mW7du5sSJE864x+Mxfn5+VdJLXFycGTFihCkpKblqrKSkxIwYMcLcc889VdLLlY4fP27Onj171fLi4mKzadOmKumh9L/PbbfdZmbMmGFOnjxZJdu9nq+++sps2LDBfP3118YYY7788kszY8YMM3XqVPPJJ59Uc3f/Ky8vr8p+h2+Ex+MxU6dOrbLtFRUVmaVLl5rRo0ebfv36mX79+pnRo0ebZcuWmaKioirr4/333zcBAQGmcePGJigoyLz//vumWbNmJiEhwfz85z83/v7+Jjs7u8r6adu2rfO7m5+fb1q0aGFCQkLMXXfdZRo3bmxCQ0PNkSNHqqSX++67z2RkZDjzf/nLX0xcXJwxxpjTp0+bTp06maeffrpKenG5XKZTp06me/fuPpPL5TJ33XWX6d69u+nRo0eV9GKMMdOnTzcNGjQwffr0MeHh4WbGjBmmSZMm5g9/+IP54x//aJo1a2YmT55cqT0QcsohODjYHDt2zBhjTOfOnc1LL73kM75kyRLTrl27KusnJSXFJCcnmy+//NJ89tlnJjk52cTExJjPP//cGFO1IScoKMh8+umnZY5/+umnJigoqEp6McaYEydOmLvuusv4+fkZf39/M3jwYJ+wU5XHxuVymfXr15tnnnnGNG3a1NStW9f88pe/NCtXrjSXL1+ukh6utH37dhMSEmJcLpdp1KiR2blzp4mJiTG33XabadWqlQkODja5ublV0ss777xz3WnOnDk1KuRUZej67LPPTMuWLU1QUJB58MEHzaOPPmoeffRR8+CDD5qgoCDTunVr89lnn1VJL/Hx8eb55583xhjzxhtvmEaNGpnnnnvOGZ8wYYL5xS9+USW9GPP9v6mCggJjjDEDBw409957rzlz5owxxpizZ8+ahIQE079//yrpJTg42Bw+fNiZv3z5sqlbt67xeDzGGGPWrVtnIiMjq6SXzMxMExMTc1XgrFOnjtm/f3+V9HClVq1amb///e/GmO//7fj7+5u//vWvzvhbb71lWrduXak9EHLKoUmTJmbnzp3GGGNCQ0NNXl6ez/ihQ4dMcHBwlfUTGhpq9uzZ48yXlJSYkSNHmltvvdUcPny4St/IW7RoYV577bUyx1977TUTHR1dJb0YY8yQIUNMXFyc+eijj0xWVpbp2rWrufPOO83p06eNMd+HHJfLVSW9XPk/5OLiYrN06VKTlJRk/P39TWRkpHnuueeq7M3KGGMSEhLMsGHDjNfrNbNmzTLNmzc3w4YNc8Yff/xxk5KSUiW9lJ7lcrlcZU5VGXJ279593Wnp0qVV1k9CQoL51a9+ZQoLC68aKywsNL/61a9MYmJilfTidrud39HLly+bOnXqmF27djnje/fuNWFhYVXSizG+/6Zatmxp1q1b5zP+4YcfmqioqCrpJTo62mzZssWZP3HihHG5XObChQvGGGOOHj1apX/g7dixw/zsZz8zzz77rCkuLjbGVF/ICQ4Odv7oNsaYunXrmn379jnzx44dM/Xq1avUHgg55TBo0CCTmppqjDHmN7/5jZk0aZLP+B//+EcTGxtbZf00aNDgmh8tpKWlmebNm5vNmzdX2f+Q582bZwIDA83TTz9t3nnnHbNt2zazbds2884775inn37aBAcHm/nz51dJL8YYExkZabZv3+7Mf/fdd6Z3796mU6dO5uuvv67yMzml/0O+0ueff26mTJlioqOjq/SNvFGjRs7vTXFxsfHz8/M5Vrm5uebf/u3fqqSXyMhIs2LFijLHP/744yo9NtcLXaXLq6qf4OBgs3fv3jLH9+zZU2V/VLndbnPo0CFnvn79+j5nL44dO1alb+Qul8ucOnXKGPP979D/PU5V2c8zzzxj2rdvb95//32zYcMG06NHD9O9e3dnfM2aNaZVq1ZV0kups2fPmiFDhpgOHTqYvXv3mrp161ZLyImJiTHvv/++McaYf/7zn8bPz88sW7bMGV+9erVp0aJFpfZAyCmHf/3rX6ZFixamW7duJj093QQHB5v777/fDB8+3HTr1s0EBASY1atXV1k/d911l/mf//mfa46lpaWZhg0bVukbxJtvvmni4uJMnTp1nDeGOnXqmLi4OLN06dIq68MYY2655Rbzz3/+02fZxYsXTUpKiunQoYPZs2dPtYecUiUlJVf9JVqZbrnlFnP06FFn/v++YX3++edV9gbRu3dv8/vf/77M8by8vCo742bM92drX3nlFXPs2LFrTqtXr66y35uIiAizcuXKMsffffddExERUSW9dOjQwXmzMub7MzcXL1505jdv3mxiYmKqpBdjvv83FRsbazp37mzq169v/va3v/mMb9q0qcqC+tmzZ82jjz7q/H/v3nvv9bkeaO3atT5v7FXpjTfeMGFhYcbPz69aQs6kSZNMs2bNzLBhw0xMTIyZMGGCufXWW82CBQvMwoULTVRUlBkzZkyl9sAt5OUQGRmpjz/+WDNmzNDKlStljNGOHTt0/Phx3Xffffrwww+r9O6hX//613rjjTc0ePDgq8bmzZunkpISLVy4sMr66du3r/r27auLFy/qq6++kiQ1bdpUdevWrbIeSrVs2VJ79uzRbbfd5iyrU6eOli9frt/85jf693//9yrrJTo6+rq3kLpcLv3iF7+osn6ioqJ05MgRtWjRQpL05ptvKiIiwhk/efKkmjZtWiW9jB07VufPny9zvHXr1vrggw+qpBdJ6tq1q06cOKHo6Ohrjp85c6bKnjkybNgwDRkyRL///e/10EMPXXXH4h/+8Ac99dRTVdLLk08+qcuXLzvz7du39xl///33q/TuqilTpvjM169f32d+5cqVVXY3Y/369bV06VJ99913unTp0lW9JCYmVkkf19KvXz/df//9ys3NLfN3ujJNnTrVueNs+PDhmjBhgjp27Khx48bpwoUL6t27t6ZPn16pPXALOaw0fvx45eXlae3atVeNXbp0SX369NHKlStVUlJSDd1Vr6lTp+r2228v83EHzz//vA4cOKC///3vVdxZ9Xv77bd1/vx5DRo06Jrj33zzjd59910NHTq0Svr5r//6L82dO1cej0cul0vS9w92Cw8P1+jRozVu3Lgq6QOorQg5sNKlS5d04cIFud3uMsf/9a9/VctfNzXdhQsX5O/vr8DAwOpuBf/f0aNHfR6wWfqsLgDXx9c6wEp16tQpM+BI338kM3Xq1CrsqPb4+uuv9eSTT1Z3GzXS8ePH9cQTT1T5dmNiYhQfH6/4+Hgn4FRXL0Btwpkc3JR2796tLl26+FxngO9xbMpWk45NTeoFqKm48BhWevfdd687fuTIkSrqpObh2JStJh2bmtQLUFtxJgdW8vPzk8vluu6dMC6X66b8K5hjU7aadGxqUi9AbcU1ObBSRESE3nrrLZWUlFxz2rVrV3W3WG04NmWrScemJvUC1FaEHFipa9euys3NLXP8h/5CthnHpmw16djUpF6A2oprcmClmvaQuZqEY1O2mnRsalIvQG3FNTkAAMBKfFwFAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFjp/wGLbvIO/j8ewgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.speaker_accent.value_counts().plot.bar()   \n",
    "\n",
    "# There is a significant class imbalance issue in speaker_accents column. As a solution we can use RandomForrestClassifier with class_weight='balanced' parameter.\n",
    "# Also when splitting the dataset, I will use the stratisfied sampling technique.\n",
    "\n",
    "# Note; hpt: forest_params = [{'max_depth': list(range(10, 15)), 'max_features': list(range(0,14))}]\n",
    "\n",
    "# use avraged F1/macro F1\n",
    "\n",
    "# <!-- # Make predictions on the test set -->\n",
    "# y_pred = classifier_pipeline.predict(X_test)\n",
    "\n",
    "# <!-- # Generate a classification report -->\n",
    "# report = classification_report(y_test, y_pred)\n",
    "\n",
    "# <!-- # Print the classification report -->\n",
    "# print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.153978</td>\n",
       "      <td>0.503276</td>\n",
       "      <td>0.022196</td>\n",
       "      <td>0.226684</td>\n",
       "      <td>0.466179</td>\n",
       "      <td>0.154995</td>\n",
       "      <td>0.195452</td>\n",
       "      <td>-0.288972</td>\n",
       "      <td>-0.297589</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.503624</td>\n",
       "      <td>-0.056849</td>\n",
       "      <td>-0.117077</td>\n",
       "      <td>0.168611</td>\n",
       "      <td>0.373346</td>\n",
       "      <td>0.037188</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.056877</td>\n",
       "      <td>0.261613</td>\n",
       "      <td>0.050610</td>\n",
       "      <td>0.097744</td>\n",
       "      <td>0.322375</td>\n",
       "      <td>-0.011609</td>\n",
       "      <td>0.201331</td>\n",
       "      <td>-0.194763</td>\n",
       "      <td>-0.194228</td>\n",
       "      <td>-0.094267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442110</td>\n",
       "      <td>0.008424</td>\n",
       "      <td>-0.067920</td>\n",
       "      <td>0.165600</td>\n",
       "      <td>0.333104</td>\n",
       "      <td>-0.270913</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.225439</td>\n",
       "      <td>0.350977</td>\n",
       "      <td>-0.295782</td>\n",
       "      <td>0.280168</td>\n",
       "      <td>0.705114</td>\n",
       "      <td>0.020545</td>\n",
       "      <td>0.390878</td>\n",
       "      <td>-0.322853</td>\n",
       "      <td>0.071575</td>\n",
       "      <td>0.013803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.380124</td>\n",
       "      <td>-0.089572</td>\n",
       "      <td>-0.023344</td>\n",
       "      <td>0.194312</td>\n",
       "      <td>0.269537</td>\n",
       "      <td>-0.292029</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.288556</td>\n",
       "      <td>0.513905</td>\n",
       "      <td>-0.205246</td>\n",
       "      <td>0.279660</td>\n",
       "      <td>0.469121</td>\n",
       "      <td>0.068339</td>\n",
       "      <td>0.131205</td>\n",
       "      <td>-0.338951</td>\n",
       "      <td>-0.270848</td>\n",
       "      <td>0.007799</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.529678</td>\n",
       "      <td>-0.093194</td>\n",
       "      <td>-0.148418</td>\n",
       "      <td>0.405543</td>\n",
       "      <td>0.438906</td>\n",
       "      <td>-0.055119</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.165176</td>\n",
       "      <td>0.312492</td>\n",
       "      <td>-0.217504</td>\n",
       "      <td>0.259960</td>\n",
       "      <td>0.568979</td>\n",
       "      <td>-0.093011</td>\n",
       "      <td>0.257977</td>\n",
       "      <td>-0.277132</td>\n",
       "      <td>-0.172113</td>\n",
       "      <td>-0.025929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.504997</td>\n",
       "      <td>-0.108256</td>\n",
       "      <td>0.036867</td>\n",
       "      <td>0.267815</td>\n",
       "      <td>0.245041</td>\n",
       "      <td>0.117444</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.153978   0.503276   0.022196   0.226684   0.466179   0.154995   \n",
       "1   0.056877   0.261613   0.050610   0.097744   0.322375  -0.011609   \n",
       "2   0.225439   0.350977  -0.295782   0.280168   0.705114   0.020545   \n",
       "3   0.288556   0.513905  -0.205246   0.279660   0.469121   0.068339   \n",
       "4   0.165176   0.312492  -0.217504   0.259960   0.568979  -0.093011   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_763  feature_764  \\\n",
       "0   0.195452  -0.288972  -0.297589   -0.008409  ...    -0.503624    -0.056849   \n",
       "1   0.201331  -0.194763  -0.194228   -0.094267  ...    -0.442110     0.008424   \n",
       "2   0.390878  -0.322853   0.071575    0.013803  ...    -0.380124    -0.089572   \n",
       "3   0.131205  -0.338951  -0.270848    0.007799  ...    -0.529678    -0.093194   \n",
       "4   0.257977  -0.277132  -0.172113   -0.025929  ...    -0.504997    -0.108256   \n",
       "\n",
       "   feature_765  feature_766  feature_767  feature_768  label_1  label_2  \\\n",
       "0    -0.117077     0.168611     0.373346     0.037188       45      NaN   \n",
       "1    -0.067920     0.165600     0.333104    -0.270913       45      NaN   \n",
       "2    -0.023344     0.194312     0.269537    -0.292029       45      NaN   \n",
       "3    -0.148418     0.405543     0.438906    -0.055119       45      NaN   \n",
       "4     0.036867     0.267815     0.245041     0.117444       45      NaN   \n",
       "\n",
       "   label_3  label_4  \n",
       "0        1        6  \n",
       "1        1        6  \n",
       "2        1        6  \n",
       "3        1        6  \n",
       "4        1        6  \n",
       "\n",
       "[5 rows x 772 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df = pd.read_csv(valid_csv_file_path)\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1      float64\n",
       "feature_2      float64\n",
       "feature_3      float64\n",
       "feature_4      float64\n",
       "feature_5      float64\n",
       "                ...   \n",
       "feature_768    float64\n",
       "label_1          int64\n",
       "label_2        float64\n",
       "label_3          int64\n",
       "label_4          int64\n",
       "Length: 772, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get type of each column\n",
    "valid_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming Labels\n",
    "\n",
    "*   Since the labels are in 'label_1', 'label_2' ... format, I will be renaming them to 'speaker_ID', 'speaker_age', ... format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df.rename(columns={'label_1': 'speaker_ID', 'label_2': 'speaker_age', 'label_3': 'speaker_gender', 'label_4': 'speaker_accent'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "      <th>speaker_ID</th>\n",
       "      <th>speaker_age</th>\n",
       "      <th>speaker_gender</th>\n",
       "      <th>speaker_accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>736.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.138566</td>\n",
       "      <td>0.326396</td>\n",
       "      <td>-0.105575</td>\n",
       "      <td>0.247640</td>\n",
       "      <td>0.473704</td>\n",
       "      <td>-0.058701</td>\n",
       "      <td>0.224979</td>\n",
       "      <td>-0.228412</td>\n",
       "      <td>-0.072824</td>\n",
       "      <td>-0.028374</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.333159</td>\n",
       "      <td>-0.044704</td>\n",
       "      <td>-0.079132</td>\n",
       "      <td>0.184085</td>\n",
       "      <td>0.323799</td>\n",
       "      <td>-0.183099</td>\n",
       "      <td>30.085333</td>\n",
       "      <td>28.330163</td>\n",
       "      <td>0.810667</td>\n",
       "      <td>6.117333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.086762</td>\n",
       "      <td>0.094890</td>\n",
       "      <td>0.152134</td>\n",
       "      <td>0.103347</td>\n",
       "      <td>0.135680</td>\n",
       "      <td>0.101014</td>\n",
       "      <td>0.117435</td>\n",
       "      <td>0.082237</td>\n",
       "      <td>0.139228</td>\n",
       "      <td>0.081750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144875</td>\n",
       "      <td>0.072396</td>\n",
       "      <td>0.064973</td>\n",
       "      <td>0.135451</td>\n",
       "      <td>0.158224</td>\n",
       "      <td>0.135559</td>\n",
       "      <td>17.489060</td>\n",
       "      <td>6.518500</td>\n",
       "      <td>0.392035</td>\n",
       "      <td>2.227895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.117159</td>\n",
       "      <td>-0.209349</td>\n",
       "      <td>-0.550758</td>\n",
       "      <td>-0.104930</td>\n",
       "      <td>-0.124913</td>\n",
       "      <td>-0.366478</td>\n",
       "      <td>-0.062692</td>\n",
       "      <td>-0.496261</td>\n",
       "      <td>-0.471700</td>\n",
       "      <td>-0.324631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.799173</td>\n",
       "      <td>-0.304076</td>\n",
       "      <td>-0.343493</td>\n",
       "      <td>-0.154304</td>\n",
       "      <td>-0.153001</td>\n",
       "      <td>-0.589591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.077579</td>\n",
       "      <td>0.270306</td>\n",
       "      <td>-0.207213</td>\n",
       "      <td>0.174754</td>\n",
       "      <td>0.396440</td>\n",
       "      <td>-0.123927</td>\n",
       "      <td>0.145534</td>\n",
       "      <td>-0.283383</td>\n",
       "      <td>-0.174644</td>\n",
       "      <td>-0.078954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.432297</td>\n",
       "      <td>-0.092119</td>\n",
       "      <td>-0.118917</td>\n",
       "      <td>0.095191</td>\n",
       "      <td>0.213669</td>\n",
       "      <td>-0.271198</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.133337</td>\n",
       "      <td>0.328736</td>\n",
       "      <td>-0.096796</td>\n",
       "      <td>0.256077</td>\n",
       "      <td>0.488115</td>\n",
       "      <td>-0.057681</td>\n",
       "      <td>0.214558</td>\n",
       "      <td>-0.227015</td>\n",
       "      <td>-0.061655</td>\n",
       "      <td>-0.029001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.338127</td>\n",
       "      <td>-0.041534</td>\n",
       "      <td>-0.079149</td>\n",
       "      <td>0.172080</td>\n",
       "      <td>0.333834</td>\n",
       "      <td>-0.186795</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.188513</td>\n",
       "      <td>0.390611</td>\n",
       "      <td>0.009080</td>\n",
       "      <td>0.322712</td>\n",
       "      <td>0.566803</td>\n",
       "      <td>0.004064</td>\n",
       "      <td>0.304288</td>\n",
       "      <td>-0.171806</td>\n",
       "      <td>0.031568</td>\n",
       "      <td>0.027306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.252013</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>-0.035977</td>\n",
       "      <td>0.273870</td>\n",
       "      <td>0.448331</td>\n",
       "      <td>-0.085947</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.424073</td>\n",
       "      <td>0.573708</td>\n",
       "      <td>0.301080</td>\n",
       "      <td>0.657954</td>\n",
       "      <td>0.819958</td>\n",
       "      <td>0.279770</td>\n",
       "      <td>0.543212</td>\n",
       "      <td>0.034650</td>\n",
       "      <td>0.337088</td>\n",
       "      <td>0.193899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351320</td>\n",
       "      <td>0.220994</td>\n",
       "      <td>0.244460</td>\n",
       "      <td>0.591306</td>\n",
       "      <td>0.649717</td>\n",
       "      <td>0.209976</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_1   feature_2   feature_3   feature_4   feature_5   feature_6  \\\n",
       "count  750.000000  750.000000  750.000000  750.000000  750.000000  750.000000   \n",
       "mean     0.138566    0.326396   -0.105575    0.247640    0.473704   -0.058701   \n",
       "std      0.086762    0.094890    0.152134    0.103347    0.135680    0.101014   \n",
       "min     -0.117159   -0.209349   -0.550758   -0.104930   -0.124913   -0.366478   \n",
       "25%      0.077579    0.270306   -0.207213    0.174754    0.396440   -0.123927   \n",
       "50%      0.133337    0.328736   -0.096796    0.256077    0.488115   -0.057681   \n",
       "75%      0.188513    0.390611    0.009080    0.322712    0.566803    0.004064   \n",
       "max      0.424073    0.573708    0.301080    0.657954    0.819958    0.279770   \n",
       "\n",
       "        feature_7   feature_8   feature_9  feature_10  ...  feature_763  \\\n",
       "count  750.000000  750.000000  750.000000  750.000000  ...   750.000000   \n",
       "mean     0.224979   -0.228412   -0.072824   -0.028374  ...    -0.333159   \n",
       "std      0.117435    0.082237    0.139228    0.081750  ...     0.144875   \n",
       "min     -0.062692   -0.496261   -0.471700   -0.324631  ...    -0.799173   \n",
       "25%      0.145534   -0.283383   -0.174644   -0.078954  ...    -0.432297   \n",
       "50%      0.214558   -0.227015   -0.061655   -0.029001  ...    -0.338127   \n",
       "75%      0.304288   -0.171806    0.031568    0.027306  ...    -0.252013   \n",
       "max      0.543212    0.034650    0.337088    0.193899  ...     0.351320   \n",
       "\n",
       "       feature_764  feature_765  feature_766  feature_767  feature_768  \\\n",
       "count   750.000000   750.000000   750.000000   750.000000   750.000000   \n",
       "mean     -0.044704    -0.079132     0.184085     0.323799    -0.183099   \n",
       "std       0.072396     0.064973     0.135451     0.158224     0.135559   \n",
       "min      -0.304076    -0.343493    -0.154304    -0.153001    -0.589591   \n",
       "25%      -0.092119    -0.118917     0.095191     0.213669    -0.271198   \n",
       "50%      -0.041534    -0.079149     0.172080     0.333834    -0.186795   \n",
       "75%      -0.000177    -0.035977     0.273870     0.448331    -0.085947   \n",
       "max       0.220994     0.244460     0.591306     0.649717     0.209976   \n",
       "\n",
       "       speaker_ID  speaker_age  speaker_gender  speaker_accent  \n",
       "count  750.000000   736.000000      750.000000      750.000000  \n",
       "mean    30.085333    28.330163        0.810667        6.117333  \n",
       "std     17.489060     6.518500        0.392035        2.227895  \n",
       "min      1.000000    22.000000        0.000000        0.000000  \n",
       "25%     15.000000    25.000000        1.000000        6.000000  \n",
       "50%     29.000000    27.000000        1.000000        6.000000  \n",
       "75%     45.000000    30.000000        1.000000        6.000000  \n",
       "max     60.000000    61.000000        1.000000       13.000000  \n",
       "\n",
       "[8 rows x 772 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for null/NaN values in all columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1         False\n",
       "feature_2         False\n",
       "feature_3         False\n",
       "feature_4         False\n",
       "feature_5         False\n",
       "                  ...  \n",
       "feature_768       False\n",
       "speaker_ID        False\n",
       "speaker_age        True\n",
       "speaker_gender    False\n",
       "speaker_accent    False\n",
       "Length: 772, dtype: bool"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.isna().any()\n",
    "\n",
    "# Based on below output we can see that there are missing values in the speaker_age column of the dataset.\n",
    "# Let's now check whether that is the only column with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1          0\n",
       "feature_2          0\n",
       "feature_3          0\n",
       "feature_4          0\n",
       "feature_5          0\n",
       "                  ..\n",
       "feature_768        0\n",
       "speaker_ID         0\n",
       "speaker_age       14\n",
       "speaker_gender     0\n",
       "speaker_accent     0\n",
       "Length: 772, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.isnull().sum().sum()\n",
    "\n",
    "# Based on the above and below outputs, we can see that there are 480 missing values 'only' in the speaker_age column. No missing values in other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation dataset shape: (750, 772)\n",
      "null values row count:  14\n",
      "null values row count percentage:  1.866666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"validation dataset shape:\", valid_df.shape)\n",
    "print(\"null values row count: \", valid_df.isnull().sum().sum())\n",
    "print(\"null values row count percentage: \", (valid_df.isnull().sum().sum() / valid_df.shape[0]) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.0    115\n",
       "27.0     81\n",
       "25.0     79\n",
       "23.0     71\n",
       "31.0     65\n",
       "30.0     48\n",
       "28.0     46\n",
       "24.0     46\n",
       "29.0     45\n",
       "22.0     36\n",
       "33.0     30\n",
       "61.0     19\n",
       "41.0     14\n",
       "34.0     11\n",
       "32.0     11\n",
       "35.0     11\n",
       "36.0      8\n",
       "Name: speaker_age, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's now check the distribution of the speaker_age column.\n",
    "valid_df.speaker_age.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Null values (Replace with Mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  28.33016304347826\n",
      "mean (rounded):  28\n"
     ]
    }
   ],
   "source": [
    "# Let's get the mean of the speaker_age column.\n",
    "speaker_age_mean = valid_df.speaker_age.mean()\n",
    "print(\"mean: \", speaker_age_mean)\n",
    "# round it to nearest int\n",
    "speaker_age_mean = round(speaker_age_mean)\n",
    "print(\"mean (rounded): \", speaker_age_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now fill the missing values with the mean value.\n",
    "valid_df.speaker_age.fillna(speaker_age_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.0    115\n",
       "27.0     81\n",
       "25.0     79\n",
       "23.0     71\n",
       "31.0     65\n",
       "28.0     60\n",
       "30.0     48\n",
       "24.0     46\n",
       "29.0     45\n",
       "22.0     36\n",
       "33.0     30\n",
       "61.0     19\n",
       "41.0     14\n",
       "34.0     11\n",
       "32.0     11\n",
       "35.0     11\n",
       "36.0      8\n",
       "Name: speaker_age, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.speaker_age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.speaker_age.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training and validation datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X = train_df.drop(['speaker_ID', 'speaker_age', 'speaker_gender', 'speaker_accent'], axis=1)\n",
    "train_speaker_IDs = train_df['speaker_ID']\n",
    "train_speaker_ages = train_df['speaker_age']\n",
    "train_speaker_genders = train_df['speaker_gender']\n",
    "train_speaker_accents = train_df['speaker_accent']\n",
    "\n",
    "valid_X = valid_df.drop(['speaker_ID', 'speaker_age', 'speaker_gender', 'speaker_accent'], axis=1)\n",
    "valid_speaker_IDs = valid_df['speaker_ID']\n",
    "valid_speaker_ages = valid_df['speaker_age']\n",
    "valid_speaker_genders = valid_df['speaker_gender']\n",
    "valid_speaker_accents = valid_df['speaker_accent']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['speaker_ID', 'speaker_age', 'speaker_gender', 'speaker_accent'], axis=1) \n",
    "y = train_df[['speaker_ID', 'speaker_age', 'speaker_gender', 'speaker_accent']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_train_X, splitted_test_X, splitted_train_Y, splitted_test_Y = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_train_speaker_IDs = splitted_train_Y['speaker_ID']\n",
    "splitted_train_speaker_ages = splitted_train_Y['speaker_age']\n",
    "splitted_train_speaker_genders = splitted_train_Y['speaker_gender']\n",
    "splitted_train_speaker_accents = splitted_train_Y['speaker_accent']\n",
    "\n",
    "splitted_test_speaker_IDs = splitted_test_Y['speaker_ID']\n",
    "splitted_test_speaker_ages = splitted_test_Y['speaker_age']\n",
    "splitted_test_speaker_genders = splitted_test_Y['speaker_gender']\n",
    "splitted_test_speaker_accents = splitted_test_Y['speaker_accent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_759</th>\n",
       "      <th>feature_760</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.124623</td>\n",
       "      <td>0.196628</td>\n",
       "      <td>0.257004</td>\n",
       "      <td>-0.156045</td>\n",
       "      <td>-0.054916</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>-0.035149</td>\n",
       "      <td>-0.092019</td>\n",
       "      <td>-0.196302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221466</td>\n",
       "      <td>0.140292</td>\n",
       "      <td>0.123622</td>\n",
       "      <td>-0.175572</td>\n",
       "      <td>-0.107030</td>\n",
       "      <td>-0.087621</td>\n",
       "      <td>-0.026501</td>\n",
       "      <td>0.139337</td>\n",
       "      <td>-0.083030</td>\n",
       "      <td>0.059507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.109655</td>\n",
       "      <td>0.170158</td>\n",
       "      <td>0.227644</td>\n",
       "      <td>-0.127088</td>\n",
       "      <td>-0.044476</td>\n",
       "      <td>-0.046852</td>\n",
       "      <td>-0.090026</td>\n",
       "      <td>-0.061321</td>\n",
       "      <td>-0.227288</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204930</td>\n",
       "      <td>0.110203</td>\n",
       "      <td>0.085665</td>\n",
       "      <td>-0.286787</td>\n",
       "      <td>-0.113195</td>\n",
       "      <td>-0.057312</td>\n",
       "      <td>-0.055680</td>\n",
       "      <td>0.143939</td>\n",
       "      <td>-0.045760</td>\n",
       "      <td>0.106113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.014854</td>\n",
       "      <td>0.030051</td>\n",
       "      <td>0.115092</td>\n",
       "      <td>-0.017179</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>-0.011692</td>\n",
       "      <td>-0.078855</td>\n",
       "      <td>-0.042991</td>\n",
       "      <td>-0.096283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032937</td>\n",
       "      <td>0.075821</td>\n",
       "      <td>0.030987</td>\n",
       "      <td>-0.149850</td>\n",
       "      <td>-0.003155</td>\n",
       "      <td>-0.010207</td>\n",
       "      <td>-0.001427</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>-0.017069</td>\n",
       "      <td>0.048123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.196893</td>\n",
       "      <td>0.113314</td>\n",
       "      <td>0.352175</td>\n",
       "      <td>-0.108499</td>\n",
       "      <td>-0.064472</td>\n",
       "      <td>-0.073239</td>\n",
       "      <td>-0.086402</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>-0.342217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255167</td>\n",
       "      <td>0.096579</td>\n",
       "      <td>0.069413</td>\n",
       "      <td>-0.215386</td>\n",
       "      <td>-0.075168</td>\n",
       "      <td>-0.035071</td>\n",
       "      <td>-0.023375</td>\n",
       "      <td>0.067768</td>\n",
       "      <td>-0.181530</td>\n",
       "      <td>0.174444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.033004</td>\n",
       "      <td>0.013373</td>\n",
       "      <td>0.124001</td>\n",
       "      <td>-0.016143</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.010635</td>\n",
       "      <td>-0.055789</td>\n",
       "      <td>-0.036282</td>\n",
       "      <td>-0.059422</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035814</td>\n",
       "      <td>0.093764</td>\n",
       "      <td>0.027321</td>\n",
       "      <td>-0.116009</td>\n",
       "      <td>0.010096</td>\n",
       "      <td>-0.042293</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>-0.007731</td>\n",
       "      <td>0.058799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   1   0.124623   0.196628   0.257004  -0.156045  -0.054916   0.006071   \n",
       "1   2   0.109655   0.170158   0.227644  -0.127088  -0.044476  -0.046852   \n",
       "2   3   0.014854   0.030051   0.115092  -0.017179   0.002720  -0.011692   \n",
       "3   4   0.196893   0.113314   0.352175  -0.108499  -0.064472  -0.073239   \n",
       "4   5   0.033004   0.013373   0.124001  -0.016143   0.010120   0.010635   \n",
       "\n",
       "   feature_7  feature_8  feature_9  ...  feature_759  feature_760  \\\n",
       "0  -0.035149  -0.092019  -0.196302  ...    -0.221466     0.140292   \n",
       "1  -0.090026  -0.061321  -0.227288  ...    -0.204930     0.110203   \n",
       "2  -0.078855  -0.042991  -0.096283  ...    -0.032937     0.075821   \n",
       "3  -0.086402   0.008671  -0.342217  ...    -0.255167     0.096579   \n",
       "4  -0.055789  -0.036282  -0.059422  ...    -0.035814     0.093764   \n",
       "\n",
       "   feature_761  feature_762  feature_763  feature_764  feature_765  \\\n",
       "0     0.123622    -0.175572    -0.107030    -0.087621    -0.026501   \n",
       "1     0.085665    -0.286787    -0.113195    -0.057312    -0.055680   \n",
       "2     0.030987    -0.149850    -0.003155    -0.010207    -0.001427   \n",
       "3     0.069413    -0.215386    -0.075168    -0.035071    -0.023375   \n",
       "4     0.027321    -0.116009     0.010096    -0.042293     0.005347   \n",
       "\n",
       "   feature_766  feature_767  feature_768  \n",
       "0     0.139337    -0.083030     0.059507  \n",
       "1     0.143939    -0.045760     0.106113  \n",
       "2     0.000934    -0.017069     0.048123  \n",
       "3     0.067768    -0.181530     0.174444  \n",
       "4     0.007722    -0.007731     0.058799  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_csv_file_path)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID               int64\n",
       "feature_1      float64\n",
       "feature_2      float64\n",
       "feature_3      float64\n",
       "feature_4      float64\n",
       "                ...   \n",
       "feature_764    float64\n",
       "feature_765    float64\n",
       "feature_766    float64\n",
       "feature_767    float64\n",
       "feature_768    float64\n",
       "Length: 769, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get type of each column\n",
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID             False\n",
       "feature_1      False\n",
       "feature_2      False\n",
       "feature_3      False\n",
       "feature_4      False\n",
       "               ...  \n",
       "feature_764    False\n",
       "feature_765    False\n",
       "feature_766    False\n",
       "feature_767    False\n",
       "feature_768    False\n",
       "Length: 769, dtype: bool"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum().sum()\n",
    "\n",
    "# based on above output we can see that there are no missing values in the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset shape: (744, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_759</th>\n",
       "      <th>feature_760</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.124623</td>\n",
       "      <td>0.196628</td>\n",
       "      <td>0.257004</td>\n",
       "      <td>-0.156045</td>\n",
       "      <td>-0.054916</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>-0.035149</td>\n",
       "      <td>-0.092019</td>\n",
       "      <td>-0.196302</td>\n",
       "      <td>0.077971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221466</td>\n",
       "      <td>0.140292</td>\n",
       "      <td>0.123622</td>\n",
       "      <td>-0.175572</td>\n",
       "      <td>-0.107030</td>\n",
       "      <td>-0.087621</td>\n",
       "      <td>-0.026501</td>\n",
       "      <td>0.139337</td>\n",
       "      <td>-0.083030</td>\n",
       "      <td>0.059507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.109655</td>\n",
       "      <td>0.170158</td>\n",
       "      <td>0.227644</td>\n",
       "      <td>-0.127088</td>\n",
       "      <td>-0.044476</td>\n",
       "      <td>-0.046852</td>\n",
       "      <td>-0.090026</td>\n",
       "      <td>-0.061321</td>\n",
       "      <td>-0.227288</td>\n",
       "      <td>0.066863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204930</td>\n",
       "      <td>0.110203</td>\n",
       "      <td>0.085665</td>\n",
       "      <td>-0.286787</td>\n",
       "      <td>-0.113195</td>\n",
       "      <td>-0.057312</td>\n",
       "      <td>-0.055680</td>\n",
       "      <td>0.143939</td>\n",
       "      <td>-0.045760</td>\n",
       "      <td>0.106113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014854</td>\n",
       "      <td>0.030051</td>\n",
       "      <td>0.115092</td>\n",
       "      <td>-0.017179</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>-0.011692</td>\n",
       "      <td>-0.078855</td>\n",
       "      <td>-0.042991</td>\n",
       "      <td>-0.096283</td>\n",
       "      <td>0.042701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032937</td>\n",
       "      <td>0.075821</td>\n",
       "      <td>0.030987</td>\n",
       "      <td>-0.149850</td>\n",
       "      <td>-0.003155</td>\n",
       "      <td>-0.010207</td>\n",
       "      <td>-0.001427</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>-0.017069</td>\n",
       "      <td>0.048123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.196893</td>\n",
       "      <td>0.113314</td>\n",
       "      <td>0.352175</td>\n",
       "      <td>-0.108499</td>\n",
       "      <td>-0.064472</td>\n",
       "      <td>-0.073239</td>\n",
       "      <td>-0.086402</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>-0.342217</td>\n",
       "      <td>0.104941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255167</td>\n",
       "      <td>0.096579</td>\n",
       "      <td>0.069413</td>\n",
       "      <td>-0.215386</td>\n",
       "      <td>-0.075168</td>\n",
       "      <td>-0.035071</td>\n",
       "      <td>-0.023375</td>\n",
       "      <td>0.067768</td>\n",
       "      <td>-0.181530</td>\n",
       "      <td>0.174444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033004</td>\n",
       "      <td>0.013373</td>\n",
       "      <td>0.124001</td>\n",
       "      <td>-0.016143</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.010635</td>\n",
       "      <td>-0.055789</td>\n",
       "      <td>-0.036282</td>\n",
       "      <td>-0.059422</td>\n",
       "      <td>0.060278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035814</td>\n",
       "      <td>0.093764</td>\n",
       "      <td>0.027321</td>\n",
       "      <td>-0.116009</td>\n",
       "      <td>0.010096</td>\n",
       "      <td>-0.042293</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>-0.007731</td>\n",
       "      <td>0.058799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.124623   0.196628   0.257004  -0.156045  -0.054916   0.006071   \n",
       "1   0.109655   0.170158   0.227644  -0.127088  -0.044476  -0.046852   \n",
       "2   0.014854   0.030051   0.115092  -0.017179   0.002720  -0.011692   \n",
       "3   0.196893   0.113314   0.352175  -0.108499  -0.064472  -0.073239   \n",
       "4   0.033004   0.013373   0.124001  -0.016143   0.010120   0.010635   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_759  feature_760  \\\n",
       "0  -0.035149  -0.092019  -0.196302    0.077971  ...    -0.221466     0.140292   \n",
       "1  -0.090026  -0.061321  -0.227288    0.066863  ...    -0.204930     0.110203   \n",
       "2  -0.078855  -0.042991  -0.096283    0.042701  ...    -0.032937     0.075821   \n",
       "3  -0.086402   0.008671  -0.342217    0.104941  ...    -0.255167     0.096579   \n",
       "4  -0.055789  -0.036282  -0.059422    0.060278  ...    -0.035814     0.093764   \n",
       "\n",
       "   feature_761  feature_762  feature_763  feature_764  feature_765  \\\n",
       "0     0.123622    -0.175572    -0.107030    -0.087621    -0.026501   \n",
       "1     0.085665    -0.286787    -0.113195    -0.057312    -0.055680   \n",
       "2     0.030987    -0.149850    -0.003155    -0.010207    -0.001427   \n",
       "3     0.069413    -0.215386    -0.075168    -0.035071    -0.023375   \n",
       "4     0.027321    -0.116009     0.010096    -0.042293     0.005347   \n",
       "\n",
       "   feature_766  feature_767  feature_768  \n",
       "0     0.139337    -0.083030     0.059507  \n",
       "1     0.143939    -0.045760     0.106113  \n",
       "2     0.000934    -0.017069     0.048123  \n",
       "3     0.067768    -0.181530     0.174444  \n",
       "4     0.007722    -0.007731     0.058799  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = test_df.drop([\"ID\"], axis=1)\n",
    "print(\"test dataset shape:\", test_X.shape)\n",
    "test_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing the Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now develop pipelines to predict the speaker ID, speaker age, speaker gender, and speaker accent. \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Speaker_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  StandardScaler => For ensuring that all features have the same scale, which is often crucial for the proper functioning of many machine learning algorithms.\n",
    "# #  PCA => For dimensionality reduction\n",
    "# #  SVC => Support Vector Classifier\n",
    "\n",
    "# # Pipeline for speaker ID prediction without feature engineering (to check raw accuracy)\n",
    "# speaker_ID_pipe_svc = Pipeline([ \n",
    "#     ('clf', SVC())\n",
    "#     ])\n",
    "\n",
    "\n",
    "# # Pipleline for speaker ID prediction with PCA for feature reduction\n",
    "# speaker_ID_pipe_scaler_pca_svc = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('pca', PCA(n_components=0.95)),\n",
    "#     ('clf', SVC())\n",
    "#     ])\n",
    "\n",
    "# # Pipleline for speaker ID prediction with Model-based feature reduction\n",
    "# speaker_ID_pipe_scaler_sfmlr_svc = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('SFM_LR', SelectFromModel(LogisticRegression(C=0.01, penalty='l1', solver='liblinear', class_weight='balanced'))),\n",
    "#     ('clf', SVC())  \n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "p2 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "p3 = Pipeline([\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "p5 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "##visualize Pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28520, 768), (28520,), (28520,), (28520,))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_speaker_IDs.shape, train_speaker_genders.shape, train_speaker_accents.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06533333333333333\n",
      "SVC:\n",
      "0.018666666666666668\n",
      "RandomForestClassifier:\n",
      "0.05333333333333334\n",
      "KNeighborsClassifier:\n",
      "0.19066666666666668\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression:\")\n",
    "p1.fit(train_X, train_speaker_IDs)\n",
    "print(p1.score(valid_X, valid_speaker_IDs))\n",
    "\n",
    "print(\"SVC:\")\n",
    "p2.fit(train_X, train_speaker_IDs)\n",
    "print(p2.score(valid_X, valid_speaker_IDs))\n",
    "\n",
    "print(\"RandomForestClassifier:\")\n",
    "p3.fit(train_X, train_speaker_IDs)\n",
    "print(p3.score(valid_X, valid_speaker_IDs))\n",
    "\n",
    "print(\"KNeighborsClassifier:\")\n",
    "p5.fit(train_X, train_speaker_IDs)\n",
    "print(p5.score(valid_X, valid_speaker_IDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FROM ABOVE EXPERIMENTES p1 (KNeighborsClassifier is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.248\n"
     ]
    }
   ],
   "source": [
    "## let's check without feature scaling\n",
    "speaker_ID_pipe_knn = Pipeline([\n",
    "    # ('scaler', StandardScaler()),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "speaker_ID_pipe_knn.fit(train_X, train_speaker_IDs)\n",
    "print(speaker_ID_pipe_knn.score(valid_X, valid_speaker_IDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy improved ==> Therefore scaling will not be kept \n",
    "# ==> Best acc right now: 0.248 (speaker_ID_pipe_knn)\n",
    "# let's now try some feature eng techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22133333333333333\n"
     ]
    }
   ],
   "source": [
    "speaker_ID_pipe_pca_knn = Pipeline([\n",
    "    # ('scaler', StandardScaler()),\n",
    "    (\"pca\", PCA(n_components=0.95)),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "speaker_ID_pipe_pca_knn.fit(train_X, train_speaker_IDs)\n",
    "print(speaker_ID_pipe_pca_knn.score(valid_X, valid_speaker_IDs))\n",
    "\n",
    "# Conclusion after running \n",
    "# => acc dropped \n",
    "# ==> Best acc right now: 0.248 (speaker_ID_pipe_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17333333333333334\n"
     ]
    }
   ],
   "source": [
    "speaker_ID_pipe_scaler_pca_knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    (\"pca\", PCA(n_components=0.95)),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "speaker_ID_pipe_scaler_pca_knn.fit(train_X, train_speaker_IDs)\n",
    "print(speaker_ID_pipe_scaler_pca_knn.score(valid_X, valid_speaker_IDs))\n",
    "\n",
    "# Conclusion after running \n",
    "# => acc dropped \n",
    "# ==> Best acc right now: 0.248 (speaker_ID_pipe_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17866666666666667\n"
     ]
    }
   ],
   "source": [
    "speaker_ID_pipe_scaler_sfm_lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('SFM_LR', SelectFromModel(LogisticRegression(C=0.01, penalty='l1', solver='liblinear', class_weight='balanced'))),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "speaker_ID_pipe_scaler_sfm_lr.fit(train_X, train_speaker_IDs)\n",
    "print(speaker_ID_pipe_scaler_sfm_lr.score(valid_X, valid_speaker_IDs))\n",
    "\n",
    "# Conclusion after running \n",
    "# => acc dropped\n",
    "# ==> Best acc right now: 0.248 (speaker_ID_pipe_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017333333333333333\n"
     ]
    }
   ],
   "source": [
    "speaker_ID_sfmlr_knn = Pipeline([\n",
    "    # ('scaler', StandardScaler()),\n",
    "    ('SFM_LR', SelectFromModel(LogisticRegression(C=0.01, penalty='l1', solver='liblinear', class_weight='balanced'))),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "speaker_ID_sfmlr_knn.fit(train_X, train_speaker_IDs)\n",
    "print(speaker_ID_sfmlr_knn.score(valid_X, valid_speaker_IDs))\n",
    "\n",
    "# Conclusion after running \n",
    "# => acc dropped\n",
    "# ==> Best acc right now: 0.248 (speaker_ID_pipe_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'classifier__n_neighbors': np.arange(1, 21),  # Number of neighbors to consider\n",
    "    'classifier__weights': ['uniform', 'distance'],  # Weighting method\n",
    "    'classifier__p': [1, 2]  # Minkowski distance parameter (1 for Manhattan, 2 for Euclidean)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=p5, param_distributions=param_grid, n_iter=20, scoring='accuracy', cv=3, n_jobs=-1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;classifier&#x27;,\n",
       "                                              KNeighborsClassifier())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={&#x27;classifier__n_neighbors&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20]),\n",
       "                                        &#x27;classifier__p&#x27;: [1, 2],\n",
       "                                        &#x27;classifier__weights&#x27;: [&#x27;uniform&#x27;,\n",
       "                                                                &#x27;distance&#x27;]},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;classifier&#x27;,\n",
       "                                              KNeighborsClassifier())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={&#x27;classifier__n_neighbors&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20]),\n",
       "                                        &#x27;classifier__p&#x27;: [1, 2],\n",
       "                                        &#x27;classifier__weights&#x27;: [&#x27;uniform&#x27;,\n",
       "                                                                &#x27;distance&#x27;]},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;classifier&#x27;, KNeighborsClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                             ('classifier',\n",
       "                                              KNeighborsClassifier())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'classifier__n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20]),\n",
       "                                        'classifier__p': [1, 2],\n",
       "                                        'classifier__weights': ['uniform',\n",
       "                                                                'distance']},\n",
       "                   scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(train_X, train_speaker_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'classifier__weights': 'distance', 'classifier__p': 2, 'classifier__n_neighbors': 9}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters: \", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24933333333333332\n"
     ]
    }
   ],
   "source": [
    "best_classifier__weights = 'distance' \n",
    "best_classifier__p = 2 \n",
    "best_classifier__n_neighbors = 9\n",
    "\n",
    "best_speaker_ID_knn = Pipeline([\n",
    "    ('classifier', KNeighborsClassifier(weights=best_classifier__weights, p=best_classifier__p, n_neighbors=best_classifier__n_neighbors))\n",
    "])\n",
    "\n",
    "best_speaker_ID_knn.fit(train_X, train_speaker_IDs)\n",
    "print(best_speaker_ID_knn.score(valid_X, valid_speaker_IDs))\n",
    "\n",
    "# Acc increased\n",
    "# ==> Best acc right now: 0.249333 (best_speaker_ID_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(744,)\n"
     ]
    }
   ],
   "source": [
    "# Let's use best performing pipeline to make predictions for the test data\n",
    "pred_test = best_speaker_ID_knn.predict(test_X)\n",
    "print(pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_1\n",
       "0       26\n",
       "1       18\n",
       "2       16\n",
       "3        7\n",
       "4       58"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = pd.DataFrame(pred_test, columns=['label_1'])\n",
    "pred_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"ID\" not in pred_test.columns:\n",
    "    pred_test.insert(0, \"ID\", test_df['ID'])\n",
    "else:\n",
    "    print(f\"Column : ID already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  label_1\n",
       "0   1       26\n",
       "1   2       18\n",
       "2   3       16\n",
       "3   4        7\n",
       "4   5       58"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Speaker_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Note: \n",
    "# There is a slight class imbalance issue in speaker_age values. As a solution we can use class_weight='balanced' parameter.\n",
    "\n",
    "# Note; hpt: forest_params = [{'max_depth': list(range(10, 15)), 'max_features': list(range(0,14))}]\n",
    "\n",
    "# use averaged F1 score \n",
    "\n",
    "# Pipeline for speaker ID prediction without feature engineering (to check raw accuracy)\n",
    "\n",
    "#Let's choose a good classifer\n",
    "\n",
    "p1 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "p2 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SVC(class_weight=\"balanced\", kernel='linear'))\n",
    "])\n",
    "\n",
    "p3 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SVC(class_weight=\"balanced\", kernel='rbf'))\n",
    "])\n",
    "\n",
    "p4 = Pipeline([\n",
    "    ('classifier', RandomForestClassifier(class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "p5 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "##visualize Pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_speaker_ages.value_counts().plot.bar()\n",
    "\n",
    "# Let's use class_weight=\"balanced\" to tackle the class imbalance issue \n",
    "# Also let's use weighted_avg metric (and F1) since it is a reliable metric when \n",
    "# class imbalance issue is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier = LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        22.0       0.19      0.22      0.21        36\n",
      "        23.0       0.31      0.06      0.10        71\n",
      "        24.0       0.12      0.04      0.06        46\n",
      "        25.0       0.00      0.00      0.00        79\n",
      "        26.0       0.18      0.24      0.20       115\n",
      "        27.0       0.23      0.23      0.23        81\n",
      "        28.0       0.08      0.03      0.05        60\n",
      "        29.0       0.00      0.00      0.00        45\n",
      "        30.0       0.00      0.00      0.00        48\n",
      "        31.0       0.11      0.23      0.15        65\n",
      "        32.0       0.17      0.36      0.24        11\n",
      "        33.0       0.05      0.10      0.07        30\n",
      "        34.0       0.08      0.18      0.11        11\n",
      "        35.0       1.00      0.27      0.43        11\n",
      "        36.0       0.04      0.75      0.07         8\n",
      "        41.0       0.12      0.07      0.09        14\n",
      "        61.0       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.13       750\n",
      "   macro avg       0.16      0.16      0.12       750\n",
      "weighted avg       0.14      0.13      0.11       750\n",
      "\n",
      "Classifier = SVC (linear)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        22.0       0.07      0.36      0.12        36\n",
      "        23.0       0.17      0.06      0.09        71\n",
      "        24.0       0.13      0.07      0.09        46\n",
      "        25.0       0.00      0.00      0.00        79\n",
      "        26.0       0.50      0.02      0.03       115\n",
      "        27.0       0.20      0.28      0.23        81\n",
      "        28.0       0.29      0.03      0.06        60\n",
      "        29.0       0.00      0.00      0.00        45\n",
      "        30.0       0.00      0.00      0.00        48\n",
      "        31.0       0.00      0.00      0.00        65\n",
      "        32.0       0.07      0.55      0.13        11\n",
      "        33.0       0.11      0.23      0.15        30\n",
      "        34.0       0.10      0.18      0.13        11\n",
      "        35.0       0.50      0.18      0.27        11\n",
      "        36.0       0.02      0.62      0.05         8\n",
      "        41.0       0.12      0.07      0.09        14\n",
      "        61.0       1.00      0.11      0.19        19\n",
      "\n",
      "    accuracy                           0.10       750\n",
      "   macro avg       0.19      0.16      0.10       750\n",
      "weighted avg       0.19      0.10      0.07       750\n",
      "\n",
      "Classifier = SVC (rbf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        22.0       0.00      0.00      0.00        36\n",
      "        23.0       0.00      0.00      0.00        71\n",
      "        24.0       0.00      0.00      0.00        46\n",
      "        25.0       0.00      0.00      0.00        79\n",
      "        26.0       0.00      0.00      0.00       115\n",
      "        27.0       0.11      1.00      0.19        81\n",
      "        28.0       0.00      0.00      0.00        60\n",
      "        29.0       0.00      0.00      0.00        45\n",
      "        30.0       0.00      0.00      0.00        48\n",
      "        31.0       0.00      0.00      0.00        65\n",
      "        32.0       0.00      0.00      0.00        11\n",
      "        33.0       0.00      0.00      0.00        30\n",
      "        34.0       0.00      0.00      0.00        11\n",
      "        35.0       0.00      0.00      0.00        11\n",
      "        36.0       0.00      0.00      0.00         8\n",
      "        41.0       0.00      0.00      0.00        14\n",
      "        61.0       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.11       750\n",
      "   macro avg       0.01      0.06      0.01       750\n",
      "weighted avg       0.01      0.11      0.02       750\n",
      "\n",
      "Classifier = RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        22.0       0.00      0.00      0.00        36\n",
      "        23.0       0.13      0.07      0.09        71\n",
      "        24.0       0.08      0.07      0.07        46\n",
      "        25.0       0.05      0.03      0.03        79\n",
      "        26.0       0.16      0.25      0.20       115\n",
      "        27.0       0.10      0.22      0.14        81\n",
      "        28.0       0.11      0.15      0.13        60\n",
      "        29.0       0.05      0.02      0.03        45\n",
      "        30.0       0.05      0.02      0.03        48\n",
      "        31.0       0.08      0.08      0.08        65\n",
      "        32.0       0.03      0.09      0.05        11\n",
      "        33.0       0.25      0.07      0.11        30\n",
      "        34.0       0.00      0.00      0.00        11\n",
      "        35.0       0.25      0.09      0.13        11\n",
      "        36.0       0.00      0.00      0.00         8\n",
      "        41.0       0.00      0.00      0.00        14\n",
      "        61.0       0.09      0.11      0.10        19\n",
      "\n",
      "    accuracy                           0.11       750\n",
      "   macro avg       0.08      0.07      0.07       750\n",
      "weighted avg       0.10      0.11      0.09       750\n",
      "\n",
      "Classifier = KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        22.0       0.22      0.22      0.22        36\n",
      "        23.0       0.18      0.20      0.19        71\n",
      "        24.0       0.14      0.50      0.22        46\n",
      "        25.0       0.28      0.09      0.13        79\n",
      "        26.0       0.37      0.32      0.35       115\n",
      "        27.0       0.40      0.27      0.32        81\n",
      "        28.0       0.21      0.45      0.29        60\n",
      "        29.0       0.39      0.27      0.32        45\n",
      "        30.0       0.26      0.10      0.15        48\n",
      "        31.0       0.15      0.05      0.07        65\n",
      "        32.0       0.11      0.27      0.15        11\n",
      "        33.0       0.59      0.33      0.43        30\n",
      "        34.0       0.07      0.27      0.11        11\n",
      "        35.0       0.75      0.55      0.63        11\n",
      "        36.0       1.00      0.25      0.40         8\n",
      "        41.0       0.00      0.00      0.00        14\n",
      "        61.0       1.00      0.11      0.19        19\n",
      "\n",
      "    accuracy                           0.25       750\n",
      "   macro avg       0.36      0.25      0.25       750\n",
      "weighted avg       0.31      0.25      0.24       750\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier = LogisticRegression\")\n",
    "p1.fit(train_X, train_speaker_ages)\n",
    "print(classification_report(valid_speaker_ages, p1.predict(valid_X)))\n",
    "\n",
    "print(\"Classifier = SVC (linear)\")\n",
    "p2.fit(train_X, train_speaker_ages)\n",
    "print(classification_report(valid_speaker_ages, p2.predict(valid_X)))\n",
    "\n",
    "print(\"Classifier = SVC (rbf)\")\n",
    "p3.fit(train_X, train_speaker_ages)\n",
    "print(classification_report(valid_speaker_ages, p3.predict(valid_X)))\n",
    "\n",
    "print(\"Classifier = RandomForestClassifier\")\n",
    "p4.fit(train_X, train_speaker_ages)\n",
    "print(classification_report(valid_speaker_ages, p4.predict(valid_X)))\n",
    "\n",
    "print(\"Classifier = KNeighborsClassifier\")\n",
    "p5.fit(train_X, train_speaker_ages)\n",
    "print(classification_report(valid_speaker_ages, p5.predict(valid_X)))\n",
    "\n",
    "# Conslusion after running:\n",
    "# best algo gives weighted avg = 0.24 (knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        22.0       0.33      0.31      0.32        36\n",
      "        23.0       0.19      0.25      0.21        71\n",
      "        24.0       0.20      0.46      0.28        46\n",
      "        25.0       0.31      0.14      0.19        79\n",
      "        26.0       0.29      0.30      0.30       115\n",
      "        27.0       0.51      0.37      0.43        81\n",
      "        28.0       0.26      0.43      0.33        60\n",
      "        29.0       0.39      0.40      0.40        45\n",
      "        30.0       0.25      0.15      0.18        48\n",
      "        31.0       0.37      0.17      0.23        65\n",
      "        32.0       0.18      0.55      0.27        11\n",
      "        33.0       0.45      0.43      0.44        30\n",
      "        34.0       0.23      0.45      0.30        11\n",
      "        35.0       0.86      0.55      0.67        11\n",
      "        36.0       1.00      0.25      0.40         8\n",
      "        41.0       0.50      0.07      0.12        14\n",
      "        61.0       0.80      0.21      0.33        19\n",
      "\n",
      "    accuracy                           0.30       750\n",
      "   macro avg       0.42      0.32      0.32       750\n",
      "weighted avg       0.35      0.30      0.30       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now let's check if we do not do feature scaling would\n",
    "# it improve the performance\n",
    "\n",
    "speaker_age_pipe_knn = Pipeline([\n",
    "    # ('scaler', StandardScaler()),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "speaker_age_pipe_knn.fit(train_X, train_speaker_ages)\n",
    "print(classification_report(valid_speaker_ages, speaker_age_pipe_knn.predict(valid_X)))\n",
    "\n",
    "# Conslusion after running \n",
    "# Weighted avg IMPROVED ==> Therefore let's use without scaling\n",
    "# Current best weighte avg = 0.30 (speaker_age_pipe_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the above outputs KNeighborsClassifier() performs better\n",
    "# Now let's check what hyperparameters performs better\n",
    "\n",
    "param_dist = {\n",
    "    'classifier__n_neighbors': np.arange(1, 21),  \n",
    "    'classifier__weights': ['uniform', 'distance'],  \n",
    "    'classifier__p': [1, 2]  # Options for the Minkowski distance metric (1 for Manhattan, 2 for Euclidean)\n",
    "}\n",
    "\n",
    "# Perform randomized search with cross-validation\n",
    "random_search = RandomizedSearchCV(speaker_age_pipe_knn, param_distributions=param_dist, n_iter=50, cv=3, scoring='balanced_accuracy', random_state=42, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV 1/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=uniform;, score=0.377 total time=   3.1s\n",
      "[CV 2/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=uniform;, score=0.436 total time=   2.7s\n",
      "[CV 3/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=uniform;, score=0.389 total time=   2.8s\n",
      "[CV 1/3] END classifier__n_neighbors=1, classifier__p=1, classifier__weights=uniform;, score=0.417 total time=  25.4s\n",
      "[CV 2/3] END classifier__n_neighbors=1, classifier__p=1, classifier__weights=uniform;, score=0.491 total time=  27.6s\n",
      "[CV 3/3] END classifier__n_neighbors=1, classifier__p=1, classifier__weights=uniform;, score=0.442 total time=  24.5s\n",
      "[CV 1/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=uniform;, score=0.379 total time=   2.9s\n",
      "[CV 2/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=uniform;, score=0.441 total time=   3.0s\n",
      "[CV 3/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=uniform;, score=0.400 total time=   2.9s\n",
      "[CV 1/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=distance;, score=0.401 total time=   2.5s\n",
      "[CV 2/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=distance;, score=0.456 total time=   2.5s\n",
      "[CV 3/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=distance;, score=0.411 total time=   2.6s\n",
      "[CV 1/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=uniform;, score=0.388 total time=   3.4s\n",
      "[CV 2/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=uniform;, score=0.448 total time=   3.6s\n",
      "[CV 3/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=uniform;, score=0.409 total time=   3.5s\n",
      "[CV 1/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=uniform;, score=0.381 total time=  36.2s\n",
      "[CV 2/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=uniform;, score=0.439 total time=  29.4s\n",
      "[CV 3/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=uniform;, score=0.394 total time=  24.8s\n",
      "[CV 1/3] END classifier__n_neighbors=3, classifier__p=2, classifier__weights=uniform;, score=0.395 total time=   3.5s\n",
      "[CV 2/3] END classifier__n_neighbors=3, classifier__p=2, classifier__weights=uniform;, score=0.451 total time=   3.5s\n",
      "[CV 3/3] END classifier__n_neighbors=3, classifier__p=2, classifier__weights=uniform;, score=0.410 total time=   3.5s\n",
      "[CV 1/3] END classifier__n_neighbors=18, classifier__p=2, classifier__weights=uniform;, score=0.343 total time=   3.6s\n",
      "[CV 2/3] END classifier__n_neighbors=18, classifier__p=2, classifier__weights=uniform;, score=0.389 total time=   3.6s\n",
      "[CV 3/3] END classifier__n_neighbors=18, classifier__p=2, classifier__weights=uniform;, score=0.353 total time=   3.6s\n",
      "[CV 1/3] END classifier__n_neighbors=2, classifier__p=1, classifier__weights=uniform;, score=0.362 total time=  34.4s\n",
      "[CV 2/3] END classifier__n_neighbors=2, classifier__p=1, classifier__weights=uniform;, score=0.434 total time=  34.5s\n",
      "[CV 3/3] END classifier__n_neighbors=2, classifier__p=1, classifier__weights=uniform;, score=0.389 total time=  35.2s\n",
      "[CV 1/3] END classifier__n_neighbors=4, classifier__p=1, classifier__weights=uniform;, score=0.394 total time=  36.3s\n",
      "[CV 2/3] END classifier__n_neighbors=4, classifier__p=1, classifier__weights=uniform;, score=0.458 total time=  24.0s\n",
      "[CV 3/3] END classifier__n_neighbors=4, classifier__p=1, classifier__weights=uniform;, score=0.411 total time=  23.6s\n",
      "[CV 1/3] END classifier__n_neighbors=13, classifier__p=1, classifier__weights=distance;, score=0.387 total time=  23.2s\n",
      "[CV 2/3] END classifier__n_neighbors=13, classifier__p=1, classifier__weights=distance;, score=0.442 total time=  24.5s\n",
      "[CV 3/3] END classifier__n_neighbors=13, classifier__p=1, classifier__weights=distance;, score=0.397 total time=  24.1s\n",
      "[CV 1/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=distance;, score=0.399 total time=  22.8s\n",
      "[CV 2/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=distance;, score=0.457 total time=  22.9s\n",
      "[CV 3/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=distance;, score=0.415 total time=  23.0s\n",
      "[CV 1/3] END classifier__n_neighbors=17, classifier__p=2, classifier__weights=distance;, score=0.371 total time=   2.5s\n",
      "[CV 2/3] END classifier__n_neighbors=17, classifier__p=2, classifier__weights=distance;, score=0.419 total time=   2.4s\n",
      "[CV 3/3] END classifier__n_neighbors=17, classifier__p=2, classifier__weights=distance;, score=0.376 total time=   2.4s\n",
      "[CV 1/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=distance;, score=0.399 total time=   2.4s\n",
      "[CV 2/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=distance;, score=0.453 total time=   2.4s\n",
      "[CV 3/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=distance;, score=0.407 total time=   2.3s\n",
      "[CV 1/3] END classifier__n_neighbors=18, classifier__p=1, classifier__weights=uniform;, score=0.353 total time=  24.2s\n",
      "[CV 2/3] END classifier__n_neighbors=18, classifier__p=1, classifier__weights=uniform;, score=0.402 total time=  23.7s\n",
      "[CV 3/3] END classifier__n_neighbors=18, classifier__p=1, classifier__weights=uniform;, score=0.362 total time=  23.2s\n",
      "[CV 1/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=distance;, score=0.392 total time=  23.7s\n",
      "[CV 2/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=distance;, score=0.446 total time=  23.0s\n",
      "[CV 3/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=distance;, score=0.404 total time=  22.6s\n",
      "[CV 1/3] END classifier__n_neighbors=19, classifier__p=1, classifier__weights=distance;, score=0.369 total time=  23.0s\n",
      "[CV 2/3] END classifier__n_neighbors=19, classifier__p=1, classifier__weights=distance;, score=0.420 total time=  23.6s\n",
      "[CV 3/3] END classifier__n_neighbors=19, classifier__p=1, classifier__weights=distance;, score=0.378 total time=  23.7s\n",
      "[CV 1/3] END classifier__n_neighbors=16, classifier__p=1, classifier__weights=distance;, score=0.378 total time=  22.9s\n",
      "[CV 2/3] END classifier__n_neighbors=16, classifier__p=1, classifier__weights=distance;, score=0.431 total time=  23.2s\n",
      "[CV 3/3] END classifier__n_neighbors=16, classifier__p=1, classifier__weights=distance;, score=0.383 total time=  22.7s\n",
      "[CV 1/3] END classifier__n_neighbors=14, classifier__p=2, classifier__weights=distance;, score=0.380 total time=   2.5s\n",
      "[CV 2/3] END classifier__n_neighbors=14, classifier__p=2, classifier__weights=distance;, score=0.433 total time=   2.5s\n",
      "[CV 3/3] END classifier__n_neighbors=14, classifier__p=2, classifier__weights=distance;, score=0.386 total time=   2.4s\n",
      "[CV 1/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=uniform;, score=0.376 total time=  23.0s\n",
      "[CV 2/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=uniform;, score=0.425 total time=  23.4s\n",
      "[CV 3/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=uniform;, score=0.384 total time=  24.0s\n",
      "[CV 1/3] END classifier__n_neighbors=3, classifier__p=1, classifier__weights=distance;, score=0.420 total time=  22.6s\n",
      "[CV 2/3] END classifier__n_neighbors=3, classifier__p=1, classifier__weights=distance;, score=0.488 total time=  22.9s\n",
      "[CV 3/3] END classifier__n_neighbors=3, classifier__p=1, classifier__weights=distance;, score=0.436 total time=  22.6s\n",
      "[CV 1/3] END classifier__n_neighbors=17, classifier__p=1, classifier__weights=uniform;, score=0.355 total time=  24.0s\n",
      "[CV 2/3] END classifier__n_neighbors=17, classifier__p=1, classifier__weights=uniform;, score=0.405 total time=  23.0s\n",
      "[CV 3/3] END classifier__n_neighbors=17, classifier__p=1, classifier__weights=uniform;, score=0.365 total time=  23.4s\n",
      "[CV 1/3] END classifier__n_neighbors=2, classifier__p=1, classifier__weights=distance;, score=0.417 total time=  35.1s\n",
      "[CV 2/3] END classifier__n_neighbors=2, classifier__p=1, classifier__weights=distance;, score=0.491 total time=  33.8s\n",
      "[CV 3/3] END classifier__n_neighbors=2, classifier__p=1, classifier__weights=distance;, score=0.442 total time=  32.6s\n",
      "[CV 1/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=distance;, score=0.388 total time=   2.5s\n",
      "[CV 2/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=distance;, score=0.442 total time=   2.5s\n",
      "[CV 3/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=distance;, score=0.396 total time=   2.4s\n",
      "[CV 1/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=uniform;, score=0.379 total time=   3.0s\n",
      "[CV 2/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=uniform;, score=0.431 total time=   2.9s\n",
      "[CV 3/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=uniform;, score=0.388 total time=   2.9s\n",
      "[CV 1/3] END classifier__n_neighbors=16, classifier__p=2, classifier__weights=uniform;, score=0.353 total time=   2.9s\n",
      "[CV 2/3] END classifier__n_neighbors=16, classifier__p=2, classifier__weights=uniform;, score=0.401 total time=   2.9s\n",
      "[CV 3/3] END classifier__n_neighbors=16, classifier__p=2, classifier__weights=uniform;, score=0.360 total time=   3.0s\n",
      "[CV 1/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=uniform;, score=0.369 total time=   2.9s\n",
      "[CV 2/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=uniform;, score=0.422 total time=   2.9s\n",
      "[CV 3/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=uniform;, score=0.376 total time=   2.9s\n",
      "[CV 1/3] END classifier__n_neighbors=14, classifier__p=2, classifier__weights=uniform;, score=0.357 total time=   2.8s\n",
      "[CV 2/3] END classifier__n_neighbors=14, classifier__p=2, classifier__weights=uniform;, score=0.412 total time=   2.9s\n",
      "[CV 3/3] END classifier__n_neighbors=14, classifier__p=2, classifier__weights=uniform;, score=0.363 total time=   2.9s\n",
      "[CV 1/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=uniform;, score=0.389 total time=  24.5s\n",
      "[CV 2/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=uniform;, score=0.452 total time=  24.0s\n",
      "[CV 3/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=uniform;, score=0.409 total time=  24.0s\n",
      "[CV 1/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=distance;, score=0.395 total time=   2.4s\n",
      "[CV 2/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=distance;, score=0.448 total time=   2.6s\n",
      "[CV 3/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=distance;, score=0.403 total time=   2.4s\n",
      "[CV 1/3] END classifier__n_neighbors=15, classifier__p=1, classifier__weights=uniform;, score=0.362 total time=  24.4s\n",
      "[CV 2/3] END classifier__n_neighbors=15, classifier__p=1, classifier__weights=uniform;, score=0.414 total time=  32.2s\n",
      "[CV 3/3] END classifier__n_neighbors=15, classifier__p=1, classifier__weights=uniform;, score=0.369 total time=  35.0s\n",
      "[CV 1/3] END classifier__n_neighbors=20, classifier__p=2, classifier__weights=distance;, score=0.361 total time=   3.6s\n",
      "[CV 2/3] END classifier__n_neighbors=20, classifier__p=2, classifier__weights=distance;, score=0.408 total time=   2.6s\n",
      "[CV 3/3] END classifier__n_neighbors=20, classifier__p=2, classifier__weights=distance;, score=0.368 total time=   2.5s\n",
      "[CV 1/3] END classifier__n_neighbors=2, classifier__p=2, classifier__weights=distance;, score=0.413 total time=   2.5s\n",
      "[CV 2/3] END classifier__n_neighbors=2, classifier__p=2, classifier__weights=distance;, score=0.486 total time=   3.3s\n",
      "[CV 3/3] END classifier__n_neighbors=2, classifier__p=2, classifier__weights=distance;, score=0.436 total time=   3.2s\n",
      "[CV 1/3] END classifier__n_neighbors=13, classifier__p=2, classifier__weights=uniform;, score=0.358 total time=   3.3s\n",
      "[CV 2/3] END classifier__n_neighbors=13, classifier__p=2, classifier__weights=uniform;, score=0.411 total time=   3.5s\n",
      "[CV 3/3] END classifier__n_neighbors=13, classifier__p=2, classifier__weights=uniform;, score=0.370 total time=   3.0s\n",
      "[CV 1/3] END classifier__n_neighbors=14, classifier__p=1, classifier__weights=distance;, score=0.385 total time=  30.3s\n",
      "[CV 2/3] END classifier__n_neighbors=14, classifier__p=1, classifier__weights=distance;, score=0.438 total time=  35.9s\n",
      "[CV 3/3] END classifier__n_neighbors=14, classifier__p=1, classifier__weights=distance;, score=0.394 total time=  32.7s\n",
      "[CV 1/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=distance;, score=0.413 total time=   3.4s\n",
      "[CV 2/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=distance;, score=0.473 total time=   3.1s\n",
      "[CV 3/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=distance;, score=0.425 total time=   3.0s\n",
      "[CV 1/3] END classifier__n_neighbors=17, classifier__p=2, classifier__weights=uniform;, score=0.349 total time=   3.3s\n",
      "[CV 2/3] END classifier__n_neighbors=17, classifier__p=2, classifier__weights=uniform;, score=0.395 total time=   3.2s\n",
      "[CV 3/3] END classifier__n_neighbors=17, classifier__p=2, classifier__weights=uniform;, score=0.355 total time=   3.2s\n",
      "[CV 1/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=distance;, score=0.407 total time=  29.3s\n",
      "[CV 2/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=distance;, score=0.467 total time=  34.0s\n",
      "[CV 3/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=distance;, score=0.421 total time=  30.0s\n",
      "[CV 1/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=uniform;, score=0.370 total time=  31.7s\n",
      "[CV 2/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=uniform;, score=0.423 total time=  33.9s\n",
      "[CV 3/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=uniform;, score=0.382 total time=  29.4s\n",
      "[CV 1/3] END classifier__n_neighbors=4, classifier__p=1, classifier__weights=distance;, score=0.418 total time=  28.3s\n",
      "[CV 2/3] END classifier__n_neighbors=4, classifier__p=1, classifier__weights=distance;, score=0.485 total time=  34.5s\n",
      "[CV 3/3] END classifier__n_neighbors=4, classifier__p=1, classifier__weights=distance;, score=0.434 total time=  33.4s\n",
      "[CV 1/3] END classifier__n_neighbors=20, classifier__p=1, classifier__weights=uniform;, score=0.350 total time=  26.1s\n",
      "[CV 2/3] END classifier__n_neighbors=20, classifier__p=1, classifier__weights=uniform;, score=0.394 total time=  34.1s\n",
      "[CV 3/3] END classifier__n_neighbors=20, classifier__p=1, classifier__weights=uniform;, score=0.350 total time=  32.4s\n",
      "[CV 1/3] END classifier__n_neighbors=1, classifier__p=2, classifier__weights=distance;, score=0.413 total time=   3.0s\n",
      "[CV 2/3] END classifier__n_neighbors=1, classifier__p=2, classifier__weights=distance;, score=0.486 total time=   3.0s\n",
      "[CV 3/3] END classifier__n_neighbors=1, classifier__p=2, classifier__weights=distance;, score=0.436 total time=   3.0s\n",
      "[CV 1/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=distance;, score=0.411 total time=  33.5s\n",
      "[CV 2/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=distance;, score=0.479 total time=  29.5s\n",
      "[CV 3/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=distance;, score=0.430 total time=  26.5s\n",
      "[CV 1/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=uniform;, score=0.372 total time=   3.1s\n",
      "[CV 2/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=uniform;, score=0.428 total time=   3.8s\n",
      "[CV 3/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=uniform;, score=0.381 total time=   3.4s\n",
      "[CV 1/3] END classifier__n_neighbors=3, classifier__p=1, classifier__weights=uniform;, score=0.398 total time=  33.3s\n",
      "[CV 2/3] END classifier__n_neighbors=3, classifier__p=1, classifier__weights=uniform;, score=0.458 total time=  25.7s\n",
      "[CV 3/3] END classifier__n_neighbors=3, classifier__p=1, classifier__weights=uniform;, score=0.415 total time=  24.6s\n",
      "[CV 1/3] END classifier__n_neighbors=17, classifier__p=1, classifier__weights=distance;, score=0.375 total time=  24.6s\n",
      "[CV 2/3] END classifier__n_neighbors=17, classifier__p=1, classifier__weights=distance;, score=0.422 total time=  24.6s\n",
      "[CV 3/3] END classifier__n_neighbors=17, classifier__p=1, classifier__weights=distance;, score=0.383 total time=  24.8s\n",
      "[CV 1/3] END classifier__n_neighbors=2, classifier__p=2, classifier__weights=uniform;, score=0.355 total time=   2.9s\n",
      "[CV 2/3] END classifier__n_neighbors=2, classifier__p=2, classifier__weights=uniform;, score=0.425 total time=   2.9s\n",
      "[CV 3/3] END classifier__n_neighbors=2, classifier__p=2, classifier__weights=uniform;, score=0.383 total time=   2.9s\n",
      "[CV 1/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=uniform;, score=0.378 total time=  25.3s\n",
      "[CV 2/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=uniform;, score=0.428 total time=  28.0s\n",
      "[CV 3/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=uniform;, score=0.386 total time=  29.6s\n",
      "[CV 1/3] END classifier__n_neighbors=19, classifier__p=1, classifier__weights=uniform;, score=0.353 total time=  30.5s\n",
      "[CV 2/3] END classifier__n_neighbors=19, classifier__p=1, classifier__weights=uniform;, score=0.398 total time=  26.2s\n",
      "[CV 3/3] END classifier__n_neighbors=19, classifier__p=1, classifier__weights=uniform;, score=0.356 total time=  27.1s\n",
      "[CV 1/3] END classifier__n_neighbors=15, classifier__p=2, classifier__weights=uniform;, score=0.357 total time=   3.1s\n",
      "[CV 2/3] END classifier__n_neighbors=15, classifier__p=2, classifier__weights=uniform;, score=0.407 total time=   3.1s\n",
      "[CV 3/3] END classifier__n_neighbors=15, classifier__p=2, classifier__weights=uniform;, score=0.362 total time=   3.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[(&#x27;classifier&#x27;,\n",
       "                                              KNeighborsClassifier())]),\n",
       "                   n_iter=50,\n",
       "                   param_distributions={&#x27;classifier__n_neighbors&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20]),\n",
       "                                        &#x27;classifier__p&#x27;: [1, 2],\n",
       "                                        &#x27;classifier__weights&#x27;: [&#x27;uniform&#x27;,\n",
       "                                                                &#x27;distance&#x27;]},\n",
       "                   random_state=42, scoring=&#x27;balanced_accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[(&#x27;classifier&#x27;,\n",
       "                                              KNeighborsClassifier())]),\n",
       "                   n_iter=50,\n",
       "                   param_distributions={&#x27;classifier__n_neighbors&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20]),\n",
       "                                        &#x27;classifier__p&#x27;: [1, 2],\n",
       "                                        &#x27;classifier__weights&#x27;: [&#x27;uniform&#x27;,\n",
       "                                                                &#x27;distance&#x27;]},\n",
       "                   random_state=42, scoring=&#x27;balanced_accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;, KNeighborsClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('classifier',\n",
       "                                              KNeighborsClassifier())]),\n",
       "                   n_iter=50,\n",
       "                   param_distributions={'classifier__n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20]),\n",
       "                                        'classifier__p': [1, 2],\n",
       "                                        'classifier__weights': ['uniform',\n",
       "                                                                'distance']},\n",
       "                   random_state=42, scoring='balanced_accuracy', verbose=3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(train_X, train_speaker_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "classifier__weights: uniform\n",
      "classifier__p: 1\n",
      "classifier__n_neighbors: 1\n"
     ]
    }
   ],
   "source": [
    "best_params = random_search.best_params_\n",
    "print(\"Best Hyperparameters:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "\n",
    "# Output\n",
    "# Best Hyperparameters:\n",
    "# classifier__weights: uniform\n",
    "# classifier__p: 1\n",
    "# classifier__n_neighbors: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        22.0       0.32      0.19      0.24        36\n",
      "        23.0       0.16      0.11      0.13        71\n",
      "        24.0       0.14      0.33      0.19        46\n",
      "        25.0       0.18      0.13      0.15        79\n",
      "        26.0       0.24      0.17      0.19       115\n",
      "        27.0       0.40      0.28      0.33        81\n",
      "        28.0       0.19      0.43      0.27        60\n",
      "        29.0       0.30      0.24      0.27        45\n",
      "        30.0       0.23      0.15      0.18        48\n",
      "        31.0       0.29      0.17      0.21        65\n",
      "        32.0       0.13      0.45      0.20        11\n",
      "        33.0       0.22      0.33      0.27        30\n",
      "        34.0       0.14      0.36      0.20        11\n",
      "        35.0       0.36      0.36      0.36        11\n",
      "        36.0       0.00      0.00      0.00         8\n",
      "        41.0       0.50      0.07      0.12        14\n",
      "        61.0       0.67      0.11      0.18        19\n",
      "\n",
      "    accuracy                           0.22       750\n",
      "   macro avg       0.26      0.23      0.21       750\n",
      "weighted avg       0.25      0.22      0.21       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's run a pipeline with the best hyperparas as well.\n",
    "best_classifier__weights = \"uniform\"\n",
    "best_classifier__p = 1\n",
    "best_classifier__n_neighbors = 1\n",
    "\n",
    "best_speaker_age_knn = Pipeline([\n",
    "    ('classifier', KNeighborsClassifier(p=best_classifier__p, n_neighbors=best_classifier__n_neighbors, weights=best_classifier__weights))\n",
    "])\n",
    "\n",
    "best_speaker_age_knn.fit(train_X, train_speaker_ages)\n",
    "print(classification_report(valid_speaker_ages, best_speaker_age_knn.predict(valid_X)))\n",
    "\n",
    "# Conclusion after runing:\n",
    "# weighted avg DROPPED\n",
    "# Current best weighte avg = 0.30 (speaker_age_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling + pca:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        22.0       0.17      0.11      0.13        36\n",
      "        23.0       0.15      0.15      0.15        71\n",
      "        24.0       0.22      0.39      0.28        46\n",
      "        25.0       0.28      0.09      0.13        79\n",
      "        26.0       0.32      0.19      0.24       115\n",
      "        27.0       0.32      0.23      0.27        81\n",
      "        28.0       0.17      0.32      0.22        60\n",
      "        29.0       0.17      0.22      0.19        45\n",
      "        30.0       0.26      0.31      0.28        48\n",
      "        31.0       0.21      0.18      0.20        65\n",
      "        32.0       0.20      0.45      0.28        11\n",
      "        33.0       0.21      0.33      0.26        30\n",
      "        34.0       0.16      0.45      0.23        11\n",
      "        35.0       0.30      0.27      0.29        11\n",
      "        36.0       0.00      0.00      0.00         8\n",
      "        41.0       0.33      0.07      0.12        14\n",
      "        61.0       1.00      0.21      0.35        19\n",
      "\n",
      "    accuracy                           0.22       750\n",
      "   macro avg       0.26      0.24      0.21       750\n",
      "weighted avg       0.26      0.22      0.22       750\n",
      "\n",
      "just pca:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        22.0       0.08      0.08      0.08        36\n",
      "        23.0       0.25      0.20      0.22        71\n",
      "        24.0       0.25      0.39      0.30        46\n",
      "        25.0       0.38      0.06      0.11        79\n",
      "        26.0       0.40      0.18      0.25       115\n",
      "        27.0       0.33      0.27      0.30        81\n",
      "        28.0       0.09      0.27      0.14        60\n",
      "        29.0       0.19      0.24      0.22        45\n",
      "        30.0       0.10      0.10      0.10        48\n",
      "        31.0       0.20      0.17      0.18        65\n",
      "        32.0       0.20      0.27      0.23        11\n",
      "        33.0       0.48      0.33      0.39        30\n",
      "        34.0       0.08      0.36      0.13        11\n",
      "        35.0       0.36      0.36      0.36        11\n",
      "        36.0       0.09      0.12      0.11         8\n",
      "        41.0       0.33      0.07      0.12        14\n",
      "        61.0       1.00      0.11      0.19        19\n",
      "\n",
      "    accuracy                           0.20       750\n",
      "   macro avg       0.28      0.21      0.20       750\n",
      "weighted avg       0.28      0.20      0.21       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's check what feature engineering technique would be better\n",
    "\n",
    "speaker_age_pipe_pca_knn = Pipeline([\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "    ('classifier', KNeighborsClassifier(weights=\"uniform\", p=1, n_neighbors=1))\n",
    "    ])\n",
    "\n",
    "print(\"just pca:\")\n",
    "speaker_age_pipe_pca_knn.fit(train_X, train_speaker_ages)\n",
    "print(classification_report(valid_speaker_ages, speaker_age_pipe_pca_knn.predict(valid_X)))\n",
    "\n",
    "print(\"scaling + pca:\")\n",
    "speaker_age_pipe_scaler_pca_knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "    ('classifier', KNeighborsClassifier(weights=\"uniform\", p=1, n_neighbors=1))\n",
    "    ])\n",
    "\n",
    "speaker_age_pipe_scaler_pca_knn.fit(train_X, train_speaker_ages)\n",
    "print(classification_report(valid_speaker_ages, speaker_age_pipe_scaler_pca_knn.predict(valid_X)))\n",
    "\n",
    "# Conclusion: Both DROPPED the weighted avg score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just model-based feature reduction:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        22.0       0.00      0.00      0.00        36\n",
      "        23.0       0.06      0.03      0.04        71\n",
      "        24.0       0.08      0.07      0.07        46\n",
      "        25.0       0.13      0.05      0.07        79\n",
      "        26.0       0.26      0.12      0.17       115\n",
      "        27.0       0.32      0.12      0.18        81\n",
      "        28.0       0.09      0.17      0.12        60\n",
      "        29.0       0.08      0.04      0.06        45\n",
      "        30.0       0.07      0.17      0.10        48\n",
      "        31.0       0.12      0.17      0.14        65\n",
      "        32.0       0.14      0.09      0.11        11\n",
      "        33.0       0.06      0.07      0.06        30\n",
      "        34.0       0.15      0.18      0.17        11\n",
      "        35.0       0.04      0.18      0.06        11\n",
      "        36.0       0.00      0.00      0.00         8\n",
      "        41.0       0.00      0.00      0.00        14\n",
      "        61.0       0.27      0.21      0.24        19\n",
      "\n",
      "    accuracy                           0.10       750\n",
      "   macro avg       0.11      0.10      0.09       750\n",
      "weighted avg       0.14      0.10      0.11       750\n",
      "\n",
      "scaling + model-based feature reduction:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        22.0       0.10      0.08      0.09        36\n",
      "        23.0       0.20      0.07      0.10        71\n",
      "        24.0       0.12      0.37      0.19        46\n",
      "        25.0       0.44      0.10      0.16        79\n",
      "        26.0       0.38      0.13      0.19       115\n",
      "        27.0       0.29      0.20      0.23        81\n",
      "        28.0       0.12      0.43      0.19        60\n",
      "        29.0       0.43      0.20      0.27        45\n",
      "        30.0       0.13      0.08      0.10        48\n",
      "        31.0       0.31      0.06      0.10        65\n",
      "        32.0       0.07      0.45      0.12        11\n",
      "        33.0       0.22      0.30      0.25        30\n",
      "        34.0       0.07      0.27      0.11        11\n",
      "        35.0       0.62      0.45      0.53        11\n",
      "        36.0       0.00      0.00      0.00         8\n",
      "        41.0       0.25      0.07      0.11        14\n",
      "        61.0       0.50      0.11      0.17        19\n",
      "\n",
      "    accuracy                           0.18       750\n",
      "   macro avg       0.25      0.20      0.17       750\n",
      "weighted avg       0.27      0.18      0.17       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pipleline for speaker age prediction with Model-based feature reduction\n",
    "speaker_age_pipe_sfmlr_knn = Pipeline([\n",
    "    ('SFM_LR', SelectFromModel(LogisticRegression(C=0.01, penalty='l1', solver='liblinear', class_weight='balanced'))),\n",
    "    ('classifier', KNeighborsClassifier(weights=\"uniform\", p=1, n_neighbors=1))\n",
    "])\n",
    "\n",
    "print(\"just model-based feature reduction:\")\n",
    "speaker_age_pipe_sfmlr_knn.fit(train_X, train_speaker_ages)\n",
    "print(classification_report(valid_speaker_ages, speaker_age_pipe_sfmlr_knn.predict(valid_X)))\n",
    "\n",
    "speaker_age_pipe_scaler_sfmlr_knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('SFM_LR', SelectFromModel(LogisticRegression(C=0.01, penalty='l1', solver='liblinear', class_weight='balanced'))),\n",
    "    ('classifier', KNeighborsClassifier(weights=\"uniform\", p=1, n_neighbors=1))\n",
    "])\n",
    "\n",
    "print(\"scaling + model-based feature reduction:\")\n",
    "speaker_age_pipe_scaler_sfmlr_knn.fit(train_X, train_speaker_ages)\n",
    "print(classification_report(valid_speaker_ages, speaker_age_pipe_scaler_sfmlr_knn.predict(valid_X)))\n",
    "\n",
    "# Conslusion\n",
    "# Both did not improve the weighted avg score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling + PCA + SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        22.0       0.00      0.00      0.00        36\n",
      "        23.0       0.00      0.00      0.00        71\n",
      "        24.0       0.00      0.00      0.00        46\n",
      "        25.0       0.00      0.00      0.00        79\n",
      "        26.0       0.00      0.00      0.00       115\n",
      "        27.0       0.11      1.00      0.19        81\n",
      "        28.0       0.00      0.00      0.00        60\n",
      "        29.0       0.00      0.00      0.00        45\n",
      "        30.0       0.00      0.00      0.00        48\n",
      "        31.0       0.00      0.00      0.00        65\n",
      "        32.0       0.00      0.00      0.00        11\n",
      "        33.0       0.00      0.00      0.00        30\n",
      "        34.0       0.00      0.00      0.00        11\n",
      "        35.0       0.00      0.00      0.00        11\n",
      "        36.0       0.00      0.00      0.00         8\n",
      "        41.0       0.00      0.00      0.00        14\n",
      "        61.0       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.11       750\n",
      "   macro avg       0.01      0.06      0.01       750\n",
      "weighted avg       0.01      0.11      0.02       750\n",
      "\n",
      "scaling + model-based feature reduction + SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        22.0       0.00      0.00      0.00        36\n",
      "        23.0       0.00      0.00      0.00        71\n",
      "        24.0       0.00      0.00      0.00        46\n",
      "        25.0       0.00      0.00      0.00        79\n",
      "        26.0       0.00      0.00      0.00       115\n",
      "        27.0       0.11      1.00      0.19        81\n",
      "        28.0       0.00      0.00      0.00        60\n",
      "        29.0       0.00      0.00      0.00        45\n",
      "        30.0       0.00      0.00      0.00        48\n",
      "        31.0       0.00      0.00      0.00        65\n",
      "        32.0       0.00      0.00      0.00        11\n",
      "        33.0       0.00      0.00      0.00        30\n",
      "        34.0       0.00      0.00      0.00        11\n",
      "        35.0       0.00      0.00      0.00        11\n",
      "        36.0       0.00      0.00      0.00         8\n",
      "        41.0       0.00      0.00      0.00        14\n",
      "        61.0       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.11       750\n",
      "   macro avg       0.01      0.06      0.01       750\n",
      "weighted avg       0.01      0.11      0.02       750\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Just for the checking purpose let's check the same pipelines but with SVC classifier as well (It should give lower weighted_avg than KNN classifier counterparts)\n",
    "\n",
    "speaker_age_pipe_scaler_pca_svc = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "    ('classifier', SVC(class_weight='balanced'))\n",
    "    ])\n",
    "\n",
    "print(\"scaling + PCA + SVC\")\n",
    "speaker_age_pipe_scaler_pca_svc.fit(train_X, train_speaker_ages)\n",
    "print(classification_report(valid_speaker_ages, speaker_age_pipe_scaler_pca_svc.predict(valid_X)))\n",
    "\n",
    "speaker_age_pipe_scaler_sfmlr_svc = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('SFM_LR', SelectFromModel(LogisticRegression(C=0.01, penalty='l1', solver='liblinear', class_weight='balanced'))),\n",
    "    ('classifier', SVC(class_weight='balanced'))\n",
    "])\n",
    "\n",
    "print(\"scaling + model-based feature reduction + SVC\")\n",
    "speaker_age_pipe_scaler_sfmlr_svc.fit(train_X, train_speaker_ages)\n",
    "print(classification_report(valid_speaker_ages, speaker_age_pipe_scaler_sfmlr_svc.predict(valid_X)))\n",
    "\n",
    "# Conclusion\n",
    "# Both did not imrpve weighted avg as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_759</th>\n",
       "      <th>feature_760</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.124623</td>\n",
       "      <td>0.196628</td>\n",
       "      <td>0.257004</td>\n",
       "      <td>-0.156045</td>\n",
       "      <td>-0.054916</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>-0.035149</td>\n",
       "      <td>-0.092019</td>\n",
       "      <td>-0.196302</td>\n",
       "      <td>0.077971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221466</td>\n",
       "      <td>0.140292</td>\n",
       "      <td>0.123622</td>\n",
       "      <td>-0.175572</td>\n",
       "      <td>-0.107030</td>\n",
       "      <td>-0.087621</td>\n",
       "      <td>-0.026501</td>\n",
       "      <td>0.139337</td>\n",
       "      <td>-0.083030</td>\n",
       "      <td>0.059507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.109655</td>\n",
       "      <td>0.170158</td>\n",
       "      <td>0.227644</td>\n",
       "      <td>-0.127088</td>\n",
       "      <td>-0.044476</td>\n",
       "      <td>-0.046852</td>\n",
       "      <td>-0.090026</td>\n",
       "      <td>-0.061321</td>\n",
       "      <td>-0.227288</td>\n",
       "      <td>0.066863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204930</td>\n",
       "      <td>0.110203</td>\n",
       "      <td>0.085665</td>\n",
       "      <td>-0.286787</td>\n",
       "      <td>-0.113195</td>\n",
       "      <td>-0.057312</td>\n",
       "      <td>-0.055680</td>\n",
       "      <td>0.143939</td>\n",
       "      <td>-0.045760</td>\n",
       "      <td>0.106113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014854</td>\n",
       "      <td>0.030051</td>\n",
       "      <td>0.115092</td>\n",
       "      <td>-0.017179</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>-0.011692</td>\n",
       "      <td>-0.078855</td>\n",
       "      <td>-0.042991</td>\n",
       "      <td>-0.096283</td>\n",
       "      <td>0.042701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032937</td>\n",
       "      <td>0.075821</td>\n",
       "      <td>0.030987</td>\n",
       "      <td>-0.149850</td>\n",
       "      <td>-0.003155</td>\n",
       "      <td>-0.010207</td>\n",
       "      <td>-0.001427</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>-0.017069</td>\n",
       "      <td>0.048123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.196893</td>\n",
       "      <td>0.113314</td>\n",
       "      <td>0.352175</td>\n",
       "      <td>-0.108499</td>\n",
       "      <td>-0.064472</td>\n",
       "      <td>-0.073239</td>\n",
       "      <td>-0.086402</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>-0.342217</td>\n",
       "      <td>0.104941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255167</td>\n",
       "      <td>0.096579</td>\n",
       "      <td>0.069413</td>\n",
       "      <td>-0.215386</td>\n",
       "      <td>-0.075168</td>\n",
       "      <td>-0.035071</td>\n",
       "      <td>-0.023375</td>\n",
       "      <td>0.067768</td>\n",
       "      <td>-0.181530</td>\n",
       "      <td>0.174444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033004</td>\n",
       "      <td>0.013373</td>\n",
       "      <td>0.124001</td>\n",
       "      <td>-0.016143</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.010635</td>\n",
       "      <td>-0.055789</td>\n",
       "      <td>-0.036282</td>\n",
       "      <td>-0.059422</td>\n",
       "      <td>0.060278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035814</td>\n",
       "      <td>0.093764</td>\n",
       "      <td>0.027321</td>\n",
       "      <td>-0.116009</td>\n",
       "      <td>0.010096</td>\n",
       "      <td>-0.042293</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>-0.007731</td>\n",
       "      <td>0.058799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.124623   0.196628   0.257004  -0.156045  -0.054916   0.006071   \n",
       "1   0.109655   0.170158   0.227644  -0.127088  -0.044476  -0.046852   \n",
       "2   0.014854   0.030051   0.115092  -0.017179   0.002720  -0.011692   \n",
       "3   0.196893   0.113314   0.352175  -0.108499  -0.064472  -0.073239   \n",
       "4   0.033004   0.013373   0.124001  -0.016143   0.010120   0.010635   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_759  feature_760  \\\n",
       "0  -0.035149  -0.092019  -0.196302    0.077971  ...    -0.221466     0.140292   \n",
       "1  -0.090026  -0.061321  -0.227288    0.066863  ...    -0.204930     0.110203   \n",
       "2  -0.078855  -0.042991  -0.096283    0.042701  ...    -0.032937     0.075821   \n",
       "3  -0.086402   0.008671  -0.342217    0.104941  ...    -0.255167     0.096579   \n",
       "4  -0.055789  -0.036282  -0.059422    0.060278  ...    -0.035814     0.093764   \n",
       "\n",
       "   feature_761  feature_762  feature_763  feature_764  feature_765  \\\n",
       "0     0.123622    -0.175572    -0.107030    -0.087621    -0.026501   \n",
       "1     0.085665    -0.286787    -0.113195    -0.057312    -0.055680   \n",
       "2     0.030987    -0.149850    -0.003155    -0.010207    -0.001427   \n",
       "3     0.069413    -0.215386    -0.075168    -0.035071    -0.023375   \n",
       "4     0.027321    -0.116009     0.010096    -0.042293     0.005347   \n",
       "\n",
       "   feature_766  feature_767  feature_768  \n",
       "0     0.139337    -0.083030     0.059507  \n",
       "1     0.143939    -0.045760     0.106113  \n",
       "2     0.000934    -0.017069     0.048123  \n",
       "3     0.067768    -0.181530     0.174444  \n",
       "4     0.007722    -0.007731     0.058799  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(744,)\n"
     ]
    }
   ],
   "source": [
    "# Let's use best performing pipeline to make predictions for the test data\n",
    "pred_speaker_ages_test = speaker_age_pipe_knn.predict(test_X)\n",
    "print(pred_speaker_ages_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_2\n",
       "0     22.0\n",
       "1     25.0\n",
       "2     30.0\n",
       "3     27.0\n",
       "4     29.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_speaker_age_test = pd.DataFrame(pred_speaker_ages_test, columns=['label_2'])\n",
    "pred_speaker_age_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  label_1\n",
       "0   1       26\n",
       "1   2       18\n",
       "2   3       16\n",
       "3   4        7\n",
       "4   5       58"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test.head() # pred_test was already created (when doing prediction of speaker_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"label_2\" not in pred_test.columns:\n",
    "    pred_test.insert(2, \"label_2\", pred_speaker_age_test['label_2'])\n",
    "else:\n",
    "    print(f\"Column : label_2 already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  label_1  label_2\n",
       "0   1       26     22.0\n",
       "1   2       18     25.0\n",
       "2   3       16     30.0\n",
       "3   4        7     27.0\n",
       "4   5       58     29.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For speaker_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.speaker_gender.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Note: \n",
    "# There is a class imbalance issue in speaker_gender values. As a solution we can use class_weight='balanced' parameter.\n",
    "# And will  use weighted avg metric when taking desicions \n",
    "\n",
    "#Let's choose a good classifer\n",
    "\n",
    "speaker_gender_scaler_lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "speaker_gender_scaler_svc_linear = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SVC(class_weight=\"balanced\", kernel='linear'))\n",
    "])\n",
    "\n",
    "speaker_gender_scaler_svc_rbf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SVC(class_weight=\"balanced\", kernel='rbf'))\n",
    "])\n",
    "\n",
    "speaker_gender_rfc = Pipeline([\n",
    "    ('classifier', RandomForestClassifier(class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "speaker_gender_scaler_knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier = LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.34      0.45       142\n",
      "           1       0.86      0.97      0.91       608\n",
      "\n",
      "    accuracy                           0.85       750\n",
      "   macro avg       0.78      0.65      0.68       750\n",
      "weighted avg       0.83      0.85      0.82       750\n",
      "\n",
      "Classifier = SVC (linear)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.81      0.55       142\n",
      "           1       0.94      0.74      0.83       608\n",
      "\n",
      "    accuracy                           0.75       750\n",
      "   macro avg       0.68      0.77      0.69       750\n",
      "weighted avg       0.84      0.75      0.78       750\n",
      "\n",
      "Classifier = SVC (rbf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       142\n",
      "           1       0.81      1.00      0.90       608\n",
      "\n",
      "    accuracy                           0.81       750\n",
      "   macro avg       0.41      0.50      0.45       750\n",
      "weighted avg       0.66      0.81      0.73       750\n",
      "\n",
      "Classifier = RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       142\n",
      "           1       0.81      1.00      0.90       608\n",
      "\n",
      "    accuracy                           0.81       750\n",
      "   macro avg       0.41      0.50      0.45       750\n",
      "weighted avg       0.66      0.81      0.73       750\n",
      "\n",
      "Classifier = KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.68      0.51       142\n",
      "           1       0.91      0.77      0.84       608\n",
      "\n",
      "    accuracy                           0.75       750\n",
      "   macro avg       0.66      0.72      0.67       750\n",
      "weighted avg       0.82      0.75      0.77       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier = LogisticRegression\")\n",
    "speaker_gender_scaler_lr.fit(train_X, train_speaker_genders)\n",
    "print(classification_report(valid_speaker_genders, speaker_gender_scaler_lr.predict(valid_X)))\n",
    "\n",
    "print(\"Classifier = SVC (linear)\")\n",
    "speaker_gender_scaler_svc_linear.fit(train_X, train_speaker_genders)\n",
    "print(classification_report(valid_speaker_genders, speaker_gender_scaler_svc_linear.predict(valid_X)))\n",
    "\n",
    "print(\"Classifier = SVC (rbf)\")\n",
    "speaker_gender_scaler_svc_rbf.fit(train_X, train_speaker_genders)\n",
    "print(classification_report(valid_speaker_genders, speaker_gender_scaler_svc_rbf.predict(valid_X)))\n",
    "\n",
    "print(\"Classifier = RandomForestClassifier\")\n",
    "speaker_gender_rfc.fit(train_X, train_speaker_genders)\n",
    "print(classification_report(valid_speaker_genders, speaker_gender_rfc.predict(valid_X)))\n",
    "\n",
    "print(\"Classifier = KNeighborsClassifier\")\n",
    "speaker_gender_scaler_knn.fit(train_X, train_speaker_genders)\n",
    "print(classification_report(valid_speaker_genders, speaker_gender_scaler_knn.predict(valid_X)))\n",
    "\n",
    "# Conslusion after running:\n",
    "# weighted avg of Logistic Regression (pipename=speaker_gender_scaler_lr)  was the highest (0.82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.63      0.68       142\n",
      "           1       0.92      0.95      0.93       608\n",
      "\n",
      "    accuracy                           0.89       750\n",
      "   macro avg       0.83      0.79      0.81       750\n",
      "weighted avg       0.88      0.89      0.88       750\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# now let's check if we do not do feature scaling would\n",
    "# it improve the performance\n",
    "\n",
    "speaker_gender_pipe_lr = Pipeline([\n",
    "    # ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(class_weight=\"balanced\"))\n",
    "])\n",
    "speaker_gender_pipe_lr.fit(train_X, train_speaker_genders)\n",
    "print(classification_report(valid_speaker_genders, speaker_gender_pipe_lr.predict(valid_X)))\n",
    "\n",
    "# Conslusion after running \n",
    "# Weighted avg IMPROVED to 0.88 ==> therefore let's not keep the feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just pca:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.72       142\n",
      "           1       0.97      0.87      0.92       608\n",
      "\n",
      "    accuracy                           0.87       750\n",
      "   macro avg       0.79      0.87      0.82       750\n",
      "weighted avg       0.90      0.87      0.88       750\n",
      "\n",
      "scaling + pca:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.68      0.62       142\n",
      "           1       0.92      0.88      0.90       608\n",
      "\n",
      "    accuracy                           0.84       750\n",
      "   macro avg       0.74      0.78      0.76       750\n",
      "weighted avg       0.85      0.84      0.85       750\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Now let's check what feature engineering technique would be better\n",
    "\n",
    "speaker_gender_pipe_pca_knn = Pipeline([\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "    ('classifier', LogisticRegression(class_weight=\"balanced\"))\n",
    "    ])\n",
    "\n",
    "print(\"just pca:\")\n",
    "speaker_gender_pipe_pca_knn.fit(train_X, train_speaker_genders)\n",
    "print(classification_report(valid_speaker_genders, speaker_gender_pipe_pca_knn.predict(valid_X)))\n",
    "\n",
    "print(\"scaling + pca:\")\n",
    "speaker_gender_pipe_scaler_pca_knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "    ('classifier', LogisticRegression(class_weight=\"balanced\"))\n",
    "    ])\n",
    "\n",
    "speaker_gender_pipe_scaler_pca_knn.fit(train_X, train_speaker_genders)\n",
    "print(classification_report(valid_speaker_genders, speaker_gender_pipe_scaler_pca_knn.predict(valid_X)))\n",
    "\n",
    "# Conclusion: jsut PCA gave the same weighted avg ==> Let's try to hyperparameter tune it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just model-based feature reduction:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.54      0.51       142\n",
      "           1       0.89      0.87      0.88       608\n",
      "\n",
      "    accuracy                           0.80       750\n",
      "   macro avg       0.68      0.70      0.69       750\n",
      "weighted avg       0.81      0.80      0.81       750\n",
      "\n",
      "scaling + model-based feature reduction:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.30      0.40       142\n",
      "           1       0.85      0.95      0.90       608\n",
      "\n",
      "    accuracy                           0.83       750\n",
      "   macro avg       0.72      0.63      0.65       750\n",
      "weighted avg       0.80      0.83      0.81       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pipleline for speaker age prediction with Model-based feature reduction\n",
    "speaker_gender_pipe_sfmlr_knn = Pipeline([\n",
    "    ('SFM_LR', SelectFromModel(LogisticRegression(C=0.01, penalty='l1', solver='liblinear', class_weight='balanced'))),\n",
    "    ('classifier', KNeighborsClassifier(weights=\"uniform\", p=1, n_neighbors=1))\n",
    "])\n",
    "\n",
    "print(\"just model-based feature reduction:\")\n",
    "speaker_gender_pipe_sfmlr_knn.fit(train_X, train_speaker_genders)\n",
    "print(classification_report(valid_speaker_genders, speaker_gender_pipe_sfmlr_knn.predict(valid_X)))\n",
    "\n",
    "speaker_gender_pipe_scaler_sfmlr_knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('SFM_LR', SelectFromModel(LogisticRegression(C=0.01, penalty='l1', solver='liblinear', class_weight='balanced'))),\n",
    "    ('classifier', KNeighborsClassifier(weights=\"uniform\", p=1, n_neighbors=1))\n",
    "])\n",
    "\n",
    "print(\"scaling + model-based feature reduction:\")\n",
    "speaker_gender_pipe_scaler_sfmlr_knn.fit(train_X, train_speaker_genders)\n",
    "print(classification_report(valid_speaker_genders, speaker_gender_pipe_scaler_sfmlr_knn.predict(valid_X)))\n",
    "\n",
    "# Conslusion\n",
    "# Both did not improve the weighted avg score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'pca__n_components': [0.90, 0.95, 0.99],  # Variance retained by PCA\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=speaker_gender_pipe_pca_knn, param_grid=param_grid, scoring='balanced_accuracy', cv=3, n_jobs=-1, verbose=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;pca&#x27;, PCA(n_components=0.95)),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        LogisticRegression(class_weight=&#x27;balanced&#x27;))]),\n",
       "             n_jobs=-1, param_grid={&#x27;pca__n_components&#x27;: [0.9, 0.95, 0.99]},\n",
       "             scoring=&#x27;balanced_accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;pca&#x27;, PCA(n_components=0.95)),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        LogisticRegression(class_weight=&#x27;balanced&#x27;))]),\n",
       "             n_jobs=-1, param_grid={&#x27;pca__n_components&#x27;: [0.9, 0.95, 0.99]},\n",
       "             scoring=&#x27;balanced_accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;pca&#x27;, PCA(n_components=0.95)),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression(class_weight=&#x27;balanced&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=0.95)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('pca', PCA(n_components=0.95)),\n",
       "                                       ('classifier',\n",
       "                                        LogisticRegression(class_weight='balanced'))]),\n",
       "             n_jobs=-1, param_grid={'pca__n_components': [0.9, 0.95, 0.99]},\n",
       "             scoring='balanced_accuracy', verbose=3)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(train_X, train_speaker_genders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Hyperparameters: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(744,)\n"
     ]
    }
   ],
   "source": [
    "best_speaker_gender_pipe = speaker_gender_pipe_lr\n",
    "pred_speaker_genders_test = best_speaker_gender_pipe.predict(test_X)\n",
    "print(pred_speaker_genders_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_3\n",
       "0        0\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_speaker_genders_test = pd.DataFrame(pred_speaker_genders_test, columns=['label_3'])\n",
    "pred_speaker_genders_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  label_1  label_2\n",
       "0   1       26     22.0\n",
       "1   2       18     25.0\n",
       "2   3       16     30.0\n",
       "3   4        7     27.0\n",
       "4   5       58     29.0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test.head() # pred_test was already created (when doing prediction of speaker_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"label_3\" not in pred_test.columns:\n",
    "    pred_test.insert(3, \"label_3\", pred_speaker_genders_test['label_3'])\n",
    "else:\n",
    "    print(f\"Column : label_3 already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  label_1  label_2  label_3\n",
       "0   1       26     22.0        0\n",
       "1   2       18     25.0        1\n",
       "2   3       16     30.0        1\n",
       "3   4        7     27.0        1\n",
       "4   5       58     29.0        0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For speaker_accent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.speaker_accent.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Note: \n",
    "# There is a class imbalance issue in speaker_accent values. As a solution we can use class_weight='balanced' parameter.\n",
    "# And will  use weighted avg metric when taking desicions \n",
    "\n",
    "#Let's choose a good classifer\n",
    "\n",
    "speaker_accent_scaler_lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "speaker_accent_scaler_svc_linear = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SVC(class_weight=\"balanced\", kernel='linear'))\n",
    "])\n",
    "\n",
    "speaker_accent_scaler_svc_rbf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SVC(class_weight=\"balanced\", kernel='rbf'))\n",
    "])\n",
    "\n",
    "speaker_accent_rfc = Pipeline([\n",
    "    ('classifier', RandomForestClassifier(class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "speaker_accent_scaler_knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier = LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       0.02      0.91      0.03        11\n",
      "           2       0.00      0.00      0.00        27\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.03      0.18      0.06        11\n",
      "           6       0.90      0.02      0.03       532\n",
      "           7       0.07      0.09      0.08        32\n",
      "           8       0.00      0.00      0.00        19\n",
      "           9       0.42      0.29      0.34        17\n",
      "          10       0.00      0.00      0.00        10\n",
      "          11       1.00      0.45      0.62        11\n",
      "          12       0.08      0.08      0.08        26\n",
      "          13       0.03      0.10      0.05        10\n",
      "\n",
      "    accuracy                           0.05       750\n",
      "   macro avg       0.18      0.15      0.09       750\n",
      "weighted avg       0.67      0.05      0.05       750\n",
      "\n",
      "Classifier = SVC (linear)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.10      0.08        21\n",
      "           1       0.03      0.91      0.06        11\n",
      "           2       0.00      0.00      0.00        27\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.10      0.36      0.16        11\n",
      "           6       0.00      0.00      0.00       532\n",
      "           7       0.05      0.12      0.07        32\n",
      "           8       1.00      0.05      0.10        19\n",
      "           9       0.07      0.41      0.13        17\n",
      "          10       0.00      0.00      0.00        10\n",
      "          11       0.67      0.18      0.29        11\n",
      "          12       0.17      0.04      0.06        26\n",
      "          13       0.03      0.50      0.05        10\n",
      "\n",
      "    accuracy                           0.05       750\n",
      "   macro avg       0.16      0.19      0.07       750\n",
      "weighted avg       0.05      0.05      0.02       750\n",
      "\n",
      "Classifier = SVC (rbf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.00      0.00      0.00        27\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00        11\n",
      "           6       0.71      1.00      0.83       532\n",
      "           7       0.00      0.00      0.00        32\n",
      "           8       0.00      0.00      0.00        19\n",
      "           9       0.00      0.00      0.00        17\n",
      "          10       0.00      0.00      0.00        10\n",
      "          11       0.00      0.00      0.00        11\n",
      "          12       0.00      0.00      0.00        26\n",
      "          13       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.71       750\n",
      "   macro avg       0.05      0.07      0.06       750\n",
      "weighted avg       0.50      0.71      0.59       750\n",
      "\n",
      "Classifier = RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.00      0.00      0.00        27\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00        11\n",
      "           6       0.71      1.00      0.83       532\n",
      "           7       0.00      0.00      0.00        32\n",
      "           8       0.00      0.00      0.00        19\n",
      "           9       0.00      0.00      0.00        17\n",
      "          10       0.00      0.00      0.00        10\n",
      "          11       0.00      0.00      0.00        11\n",
      "          12       0.00      0.00      0.00        26\n",
      "          13       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.71       750\n",
      "   macro avg       0.05      0.07      0.06       750\n",
      "weighted avg       0.50      0.71      0.59       750\n",
      "\n",
      "Classifier = KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.19      0.21        21\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.50      0.19      0.27        27\n",
      "           3       1.00      0.12      0.22         8\n",
      "           4       0.07      0.13      0.10        15\n",
      "           5       0.09      0.27      0.13        11\n",
      "           6       0.75      0.86      0.80       532\n",
      "           7       0.00      0.00      0.00        32\n",
      "           8       0.00      0.00      0.00        19\n",
      "           9       0.15      0.12      0.13        17\n",
      "          10       0.12      0.10      0.11        10\n",
      "          11       0.86      0.55      0.67        11\n",
      "          12       0.27      0.12      0.16        26\n",
      "          13       0.75      0.30      0.43        10\n",
      "\n",
      "    accuracy                           0.65       750\n",
      "   macro avg       0.34      0.21      0.23       750\n",
      "weighted avg       0.60      0.65      0.62       750\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier = LogisticRegression\")\n",
    "speaker_accent_scaler_lr.fit(train_X, train_speaker_accents)\n",
    "print(classification_report(valid_speaker_accents, speaker_accent_scaler_lr.predict(valid_X)))\n",
    "\n",
    "print(\"Classifier = SVC (linear)\")\n",
    "speaker_accent_scaler_svc_linear.fit(train_X, train_speaker_accents)\n",
    "print(classification_report(valid_speaker_accents, speaker_accent_scaler_svc_linear.predict(valid_X)))\n",
    "\n",
    "print(\"Classifier = SVC (rbf)\")\n",
    "speaker_accent_scaler_svc_rbf.fit(train_X, train_speaker_accents)\n",
    "print(classification_report(valid_speaker_accents, speaker_accent_scaler_svc_rbf.predict(valid_X)))\n",
    "\n",
    "print(\"Classifier = RandomForestClassifier\")\n",
    "speaker_accent_rfc.fit(train_X, train_speaker_accents)\n",
    "print(classification_report(valid_speaker_accents, speaker_accent_rfc.predict(valid_X)))\n",
    "\n",
    "print(\"Classifier = KNeighborsClassifier\")\n",
    "speaker_accent_scaler_knn.fit(train_X, train_speaker_accents)\n",
    "print(classification_report(valid_speaker_accents, speaker_accent_scaler_knn.predict(valid_X)))\n",
    "\n",
    "# Conslusion after running:\n",
    "# weighted avg of KNN was the best: 0.62       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier = SVC (linear) without feature scaling\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.38      0.27        21\n",
      "           1       0.67      0.18      0.29        11\n",
      "           2       0.27      0.11      0.16        27\n",
      "           3       1.00      0.38      0.55         8\n",
      "           4       0.33      0.20      0.25        15\n",
      "           5       0.26      0.55      0.35        11\n",
      "           6       0.77      0.84      0.80       532\n",
      "           7       0.23      0.09      0.13        32\n",
      "           8       0.00      0.00      0.00        19\n",
      "           9       0.15      0.12      0.13        17\n",
      "          10       0.23      0.30      0.26        10\n",
      "          11       0.86      0.55      0.67        11\n",
      "          12       0.21      0.23      0.22        26\n",
      "          13       1.00      0.30      0.46        10\n",
      "\n",
      "    accuracy                           0.66       750\n",
      "   macro avg       0.44      0.30      0.32       750\n",
      "weighted avg       0.64      0.66      0.64       750\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Let's now check whether the feature sclaing helps the weighted svg score or not\n",
    "\n",
    "speaker_accent_knn = Pipeline([\n",
    "    # ('scaler', StandardScaler()),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "print(\"Classifier = SVC (linear) without feature scaling\")\n",
    "speaker_accent_knn.fit(train_X, train_speaker_accents)\n",
    "print(classification_report(valid_speaker_accents, speaker_accent_knn.predict(valid_X)))\n",
    "\n",
    "# Conclusion\n",
    "# weighted avg IMPROVED : 0.64 (from 0.62)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'classifier__n_neighbors': range(1, 21),  # Number of neighbors to consider\n",
    "    'classifier__weights': ['uniform', 'distance'],  # Weighting method\n",
    "    'classifier__p': [1, 2],  # Minkowski distance parameter (1 for Manhattan, 2 for Euclidean)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=speaker_accent_knn,  # Your pipeline\n",
    "    param_distributions=param_dist,  # The hyperparameters to search over\n",
    "    n_iter=10,  # Number of parameter settings that are sampled\n",
    "    scoring='balanced_accuracy',  # You can use other scoring metrics if needed\n",
    "    cv=3,  # Number of cross-validation folds\n",
    "    n_jobs=-1,  # Use all available CPU cores\n",
    "    verbose=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\ACA semester 7\\CS4622 - Machine Learning\\ML-Project\\Coding\\Competition1-Layer12(using valid dataset).ipynb Cell 138\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/ACA%20semester%207/CS4622%20-%20Machine%20Learning/ML-Project/Coding/Competition1-Layer12%28using%20valid%20dataset%29.ipynb#Y306sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m random_search\u001b[39m.\u001b[39;49mfit(train_X, train_speaker_accents)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1767\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1768\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1769\u001b[0m         ParameterSampler(\n\u001b[0;32m   1770\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[0;32m   1771\u001b[0m         )\n\u001b[0;32m   1772\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random_search.fit(train_X, train_speaker_accents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "{'classifier__C': 0.01, 'classifier__gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters:\")\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best weighted avg as of now: 0.64 (speaker_accent_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just pca:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.38      0.22        21\n",
      "           1       1.00      0.09      0.17        11\n",
      "           2       0.40      0.15      0.22        27\n",
      "           3       1.00      0.38      0.55         8\n",
      "           4       0.15      0.20      0.17        15\n",
      "           5       0.16      0.27      0.20        11\n",
      "           6       0.76      0.82      0.79       532\n",
      "           7       0.14      0.06      0.09        32\n",
      "           8       0.00      0.00      0.00        19\n",
      "           9       0.14      0.12      0.13        17\n",
      "          10       0.19      0.30      0.23        10\n",
      "          11       0.86      0.55      0.67        11\n",
      "          12       0.44      0.27      0.33        26\n",
      "          13       1.00      0.30      0.46        10\n",
      "\n",
      "    accuracy                           0.64       750\n",
      "   macro avg       0.46      0.28      0.30       750\n",
      "weighted avg       0.64      0.64      0.62       750\n",
      "\n",
      "scaling + pca:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.24      0.25        21\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.46      0.22      0.30        27\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.10      0.33      0.16        15\n",
      "           5       0.14      0.36      0.21        11\n",
      "           6       0.75      0.80      0.77       532\n",
      "           7       0.33      0.03      0.06        32\n",
      "           8       0.00      0.00      0.00        19\n",
      "           9       0.03      0.06      0.04        17\n",
      "          10       0.05      0.10      0.07        10\n",
      "          11       0.80      0.36      0.50        11\n",
      "          12       0.27      0.12      0.16        26\n",
      "          13       1.00      0.30      0.46        10\n",
      "\n",
      "    accuracy                           0.61       750\n",
      "   macro avg       0.30      0.21      0.21       750\n",
      "weighted avg       0.61      0.61      0.60       750\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Now let's check what feature engineering technique would be better\n",
    "\n",
    "speaker_accent_pipe_pca_knn = Pipeline([\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "print(\"just pca:\")\n",
    "speaker_accent_pipe_pca_knn.fit(train_X, train_speaker_accents)\n",
    "print(classification_report(valid_speaker_accents, speaker_accent_pipe_pca_knn.predict(valid_X)))\n",
    "\n",
    "print(\"scaling + pca:\")\n",
    "speaker_accent_pipe_scaler_pca_knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "speaker_accent_pipe_scaler_pca_knn.fit(train_X, train_speaker_accents)\n",
    "print(classification_report(valid_speaker_accents, speaker_accent_pipe_scaler_pca_knn.predict(valid_X)))\n",
    "\n",
    "# Conclusion: jsut PCA gave the same weighted avg ==> Let's try to hyperparameter tune it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just model-based feature reduction:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.14      0.16        21\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.00      0.00      0.00        27\n",
      "           3       0.20      0.25      0.22         8\n",
      "           4       0.30      0.20      0.24        15\n",
      "           5       0.06      0.09      0.07        11\n",
      "           6       0.74      0.90      0.82       532\n",
      "           7       0.50      0.16      0.24        32\n",
      "           8       0.00      0.00      0.00        19\n",
      "           9       0.00      0.00      0.00        17\n",
      "          10       0.33      0.10      0.15        10\n",
      "          11       0.33      0.27      0.30        11\n",
      "          12       0.17      0.08      0.11        26\n",
      "          13       0.14      0.10      0.12        10\n",
      "\n",
      "    accuracy                           0.67       750\n",
      "   macro avg       0.21      0.16      0.17       750\n",
      "weighted avg       0.58      0.67      0.61       750\n",
      "\n",
      "scaling + model-based feature reduction:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.29      0.28        21\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.27      0.11      0.16        27\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.29      0.13      0.18        15\n",
      "           5       0.12      0.36      0.18        11\n",
      "           6       0.76      0.87      0.81       532\n",
      "           7       0.25      0.03      0.06        32\n",
      "           8       0.00      0.00      0.00        19\n",
      "           9       0.24      0.29      0.26        17\n",
      "          10       0.20      0.10      0.13        10\n",
      "          11       0.56      0.45      0.50        11\n",
      "          12       0.14      0.15      0.15        26\n",
      "          13       0.33      0.10      0.15        10\n",
      "\n",
      "    accuracy                           0.66       750\n",
      "   macro avg       0.25      0.21      0.20       750\n",
      "weighted avg       0.60      0.66      0.62       750\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Pipleline for speaker age prediction with Model-based feature reduction\n",
    "speaker_accent_pipe_sfmlr_knn = Pipeline([\n",
    "    ('SFM_LR', SelectFromModel(LogisticRegression(C=0.01, penalty='l1', solver='liblinear', class_weight='balanced'))),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "print(\"just model-based feature reduction:\")\n",
    "speaker_accent_pipe_sfmlr_knn.fit(train_X, train_speaker_accents)\n",
    "print(classification_report(valid_speaker_accents, speaker_accent_pipe_sfmlr_knn.predict(valid_X)))\n",
    "\n",
    "speaker_accent_pipe_scaler_sfmlr_knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('SFM_LR', SelectFromModel(LogisticRegression(C=0.01, penalty='l1', solver='liblinear', class_weight='balanced'))),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "print(\"scaling + model-based feature reduction:\")\n",
    "speaker_accent_pipe_scaler_sfmlr_knn.fit(train_X, train_speaker_accents)\n",
    "print(classification_report(valid_speaker_accents, speaker_accent_pipe_scaler_sfmlr_knn.predict(valid_X)))\n",
    "\n",
    "# Conslusion\n",
    "# Both did not improve the weighted avg score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_759</th>\n",
       "      <th>feature_760</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.124623</td>\n",
       "      <td>0.196628</td>\n",
       "      <td>0.257004</td>\n",
       "      <td>-0.156045</td>\n",
       "      <td>-0.054916</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>-0.035149</td>\n",
       "      <td>-0.092019</td>\n",
       "      <td>-0.196302</td>\n",
       "      <td>0.077971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221466</td>\n",
       "      <td>0.140292</td>\n",
       "      <td>0.123622</td>\n",
       "      <td>-0.175572</td>\n",
       "      <td>-0.107030</td>\n",
       "      <td>-0.087621</td>\n",
       "      <td>-0.026501</td>\n",
       "      <td>0.139337</td>\n",
       "      <td>-0.083030</td>\n",
       "      <td>0.059507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.109655</td>\n",
       "      <td>0.170158</td>\n",
       "      <td>0.227644</td>\n",
       "      <td>-0.127088</td>\n",
       "      <td>-0.044476</td>\n",
       "      <td>-0.046852</td>\n",
       "      <td>-0.090026</td>\n",
       "      <td>-0.061321</td>\n",
       "      <td>-0.227288</td>\n",
       "      <td>0.066863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204930</td>\n",
       "      <td>0.110203</td>\n",
       "      <td>0.085665</td>\n",
       "      <td>-0.286787</td>\n",
       "      <td>-0.113195</td>\n",
       "      <td>-0.057312</td>\n",
       "      <td>-0.055680</td>\n",
       "      <td>0.143939</td>\n",
       "      <td>-0.045760</td>\n",
       "      <td>0.106113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014854</td>\n",
       "      <td>0.030051</td>\n",
       "      <td>0.115092</td>\n",
       "      <td>-0.017179</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>-0.011692</td>\n",
       "      <td>-0.078855</td>\n",
       "      <td>-0.042991</td>\n",
       "      <td>-0.096283</td>\n",
       "      <td>0.042701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032937</td>\n",
       "      <td>0.075821</td>\n",
       "      <td>0.030987</td>\n",
       "      <td>-0.149850</td>\n",
       "      <td>-0.003155</td>\n",
       "      <td>-0.010207</td>\n",
       "      <td>-0.001427</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>-0.017069</td>\n",
       "      <td>0.048123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.196893</td>\n",
       "      <td>0.113314</td>\n",
       "      <td>0.352175</td>\n",
       "      <td>-0.108499</td>\n",
       "      <td>-0.064472</td>\n",
       "      <td>-0.073239</td>\n",
       "      <td>-0.086402</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>-0.342217</td>\n",
       "      <td>0.104941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255167</td>\n",
       "      <td>0.096579</td>\n",
       "      <td>0.069413</td>\n",
       "      <td>-0.215386</td>\n",
       "      <td>-0.075168</td>\n",
       "      <td>-0.035071</td>\n",
       "      <td>-0.023375</td>\n",
       "      <td>0.067768</td>\n",
       "      <td>-0.181530</td>\n",
       "      <td>0.174444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033004</td>\n",
       "      <td>0.013373</td>\n",
       "      <td>0.124001</td>\n",
       "      <td>-0.016143</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.010635</td>\n",
       "      <td>-0.055789</td>\n",
       "      <td>-0.036282</td>\n",
       "      <td>-0.059422</td>\n",
       "      <td>0.060278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035814</td>\n",
       "      <td>0.093764</td>\n",
       "      <td>0.027321</td>\n",
       "      <td>-0.116009</td>\n",
       "      <td>0.010096</td>\n",
       "      <td>-0.042293</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>-0.007731</td>\n",
       "      <td>0.058799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.124623   0.196628   0.257004  -0.156045  -0.054916   0.006071   \n",
       "1   0.109655   0.170158   0.227644  -0.127088  -0.044476  -0.046852   \n",
       "2   0.014854   0.030051   0.115092  -0.017179   0.002720  -0.011692   \n",
       "3   0.196893   0.113314   0.352175  -0.108499  -0.064472  -0.073239   \n",
       "4   0.033004   0.013373   0.124001  -0.016143   0.010120   0.010635   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_759  feature_760  \\\n",
       "0  -0.035149  -0.092019  -0.196302    0.077971  ...    -0.221466     0.140292   \n",
       "1  -0.090026  -0.061321  -0.227288    0.066863  ...    -0.204930     0.110203   \n",
       "2  -0.078855  -0.042991  -0.096283    0.042701  ...    -0.032937     0.075821   \n",
       "3  -0.086402   0.008671  -0.342217    0.104941  ...    -0.255167     0.096579   \n",
       "4  -0.055789  -0.036282  -0.059422    0.060278  ...    -0.035814     0.093764   \n",
       "\n",
       "   feature_761  feature_762  feature_763  feature_764  feature_765  \\\n",
       "0     0.123622    -0.175572    -0.107030    -0.087621    -0.026501   \n",
       "1     0.085665    -0.286787    -0.113195    -0.057312    -0.055680   \n",
       "2     0.030987    -0.149850    -0.003155    -0.010207    -0.001427   \n",
       "3     0.069413    -0.215386    -0.075168    -0.035071    -0.023375   \n",
       "4     0.027321    -0.116009     0.010096    -0.042293     0.005347   \n",
       "\n",
       "   feature_766  feature_767  feature_768  \n",
       "0     0.139337    -0.083030     0.059507  \n",
       "1     0.143939    -0.045760     0.106113  \n",
       "2     0.000934    -0.017069     0.048123  \n",
       "3     0.067768    -0.181530     0.174444  \n",
       "4     0.007722    -0.007731     0.058799  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(744,)\n"
     ]
    }
   ],
   "source": [
    "pred_speaker_accents_test = speaker_accent_knn.predict(test_X)\n",
    "print(pred_speaker_accents_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_4\n",
       "0        2\n",
       "1        8\n",
       "2        6\n",
       "3        6\n",
       "4        6"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_speaker_accents_test = pd.DataFrame(pred_speaker_accents_test, columns=['label_4'])\n",
    "pred_speaker_accents_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  label_1  label_2  label_3\n",
       "0   1       26     22.0        0\n",
       "1   2       18     25.0        1\n",
       "2   3       16     30.0        1\n",
       "3   4        7     27.0        1\n",
       "4   5       58     29.0        0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test.head() # pred_test was already created (when doing prediction of speaker_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"label_4\" not in pred_test.columns:\n",
    "    pred_test.insert(4, \"label_4\", pred_speaker_accents_test['label_4'])\n",
    "else:\n",
    "    print(f\"Column : label_4 already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  label_1  label_2  label_3  label_4\n",
       "0   1       26     22.0        0        2\n",
       "1   2       18     25.0        1        8\n",
       "2   3       16     30.0        1        6\n",
       "3   4        7     27.0        1        6\n",
       "4   5       58     29.0        0        6"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  label_1  label_2  label_3  label_4\n",
       "0   1       26     22.0        0        2\n",
       "1   2       18     25.0        1        8\n",
       "2   3       16     30.0        1        6\n",
       "3   4        7     27.0        1        6\n",
       "4   5       58     29.0        0        6"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_layer7 = pred_test\n",
    "pred_test_layer7.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_layer7.to_csv('2 - 190290U_pred_test_layer12.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #################### RUN BELOW FOR THE BEST MODEL ####################\n",
    "\n",
    "# # After grid search is complete, save the best estimator\n",
    "# best_svm = grid_search.best_estimator_\n",
    "\n",
    "# # You can also save the best hyperparameters\n",
    "# best_params = grid_search.best_params_\n",
    "\n",
    "# # Now, you can use the best estimator for making predictions or further operations\n",
    "# y_pred = best_svm.predict(X_validation)  # Example: Using it for predictions on validation data\n",
    "\n",
    "# # If you want to create a new instance of the model with the best hyperparameters\n",
    "# svm_with_best_params = SVC(**best_params)\n",
    "# svm_with_best_params.fit(X_train, y_train)  # Train the new model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all other labels (age, gender, accent) have class imbalance problem. So account for that -> I think cv parameter in grid search cv can be used for that\n",
    "# read about it ==> https://scikit-learn.org/stable/modules/cross_validation.html (Cross validation)\n",
    "# This is vital because, we cannot track the model performance using a single metric\n",
    "# if cv is given an integer value, it will use stratified k fold cross validation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSNE : feature rection technique\n",
    "\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from scipy.stats import uniform\n",
    "\n",
    "# # Define a range of hyperparameters and their distributions for random search\n",
    "# param_dist = {\n",
    "#     'clf__C': uniform(loc=0.1, scale=10),  # Regularization parameter (uniform distribution)\n",
    "#     'clf__kernel': ['linear', 'rbf', 'poly'],  # Kernel type\n",
    "# }\n",
    "\n",
    "# # Create a random search object\n",
    "# random_search = RandomizedSearchCV(estimator=speaker_ID_pipe_scaler_svc, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
    "\n",
    "# # Fit the random search to the data\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# # Get the best hyperparameters\n",
    "# best_params_random = random_search.best_params_\n",
    "# best_accuracy_random = random_search.best_score_\n",
    "\n",
    "# print(\"Best Hyperparameters (Random Search):\", best_params_random)\n",
    "# print(\"Best Accuracy (Random Search):\", best_accuracy_random)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to compare different pipelines\n",
    "\n",
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Load a sample dataset (Iris dataset in this example)\n",
    "# data = load_iris()\n",
    "# X, y = data.data, data.target\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create a common feature scaling pipeline\n",
    "# common_preprocessing = Pipeline([\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# # Define pipelines with different feature reduction techniques on top of common preprocessing\n",
    "# # You can add more as needed\n",
    "# pca_pipeline = Pipeline([\n",
    "#     ('preprocessing', common_preprocessing),\n",
    "#     ('pca', PCA(n_components=2)),  # Adjust the number of components as needed\n",
    "#     ('clf', SVC()),\n",
    "# ])\n",
    "\n",
    "# tsne_pipeline = Pipeline([\n",
    "#     ('preprocessing', common_preprocessing),\n",
    "#     ('tsne', TSNE(n_components=2)),  # Adjust the number of components as needed\n",
    "#     ('clf', SVC()),\n",
    "# ])\n",
    "\n",
    "# selectkbest_pipe = Pipeline([\n",
    "#     ('preprocessing', common_preprocessing),\n",
    "#     ('SelectKBest', SelectKBest(chi2, k=10)),\n",
    "#     ('clf', SVC())\n",
    "# ])\n",
    "\n",
    "# # Create a list of feature reduction pipelines for easy iteration\n",
    "# feature_reduction_pipelines = [\n",
    "#     (\"PCA\", pca_pipeline),\n",
    "#     (\"t-SNE\", tsne_pipeline),\n",
    "# ]\n",
    "\n",
    "# # Fit and compare the performance of different feature reduction pipelines\n",
    "# for name, pipeline in feature_reduction_pipelines:\n",
    "#     # Fit the pipeline on the training data\n",
    "#     pipeline.fit(X_train, y_train)\n",
    "    \n",
    "#     # Make predictions on the testing data\n",
    "#     y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "#     # Calculate and print the accuracy\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     print(f\"Accuracy with {name}: {accuracy:.2f}\")\n",
    "\n",
    "########################################################################################\n",
    "###########So we effectively fit the scaler pipeline 2 times right? is it the case?################################\n",
    "########################################################################################\n",
    "########################################################################################\n",
    "\n",
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Load a sample dataset (Iris dataset in this example)\n",
    "# data = load_iris()\n",
    "# X, y = data.data, data.target\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create a common feature scaling pipeline and fit it once\n",
    "# common_preprocessing = Pipeline([\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# # Fit the common preprocessing pipeline on the training data\n",
    "# common_preprocessing.fit(X_train)\n",
    "\n",
    "# # Define pipelines with different feature reduction techniques using the fitted common preprocessing\n",
    "# # You can add more as needed\n",
    "# pca_pipeline = Pipeline([\n",
    "#     ('preprocessing', common_preprocessing),\n",
    "#     ('pca', PCA(n_components=2)),  # Adjust the number of components as needed\n",
    "#     ('clf', SVC()),\n",
    "# ])\n",
    "\n",
    "# tsne_pipeline = Pipeline([\n",
    "#     ('preprocessing', common_preprocessing),\n",
    "#     ('tsne', TSNE(n_components=2)),  # Adjust the number of components as needed\n",
    "#     ('clf', SVC()),\n",
    "# ])\n",
    "\n",
    "# # Create a list of feature reduction pipelines for easy iteration\n",
    "# feature_reduction_pipelines = [\n",
    "#     (\"PCA\", pca_pipeline),\n",
    "#     (\"t-SNE\", tsne_pipeline),\n",
    "# ]\n",
    "\n",
    "# # Fit and compare the performance of different feature reduction pipelines\n",
    "# for name, pipeline in feature_reduction_pipelines:\n",
    "#     # Make predictions on the testing data using the fitted common preprocessing\n",
    "#     X_test_preprocessed = pipeline.named_steps['preprocessing'].transform(X_test)\n",
    "#     y_pred = pipeline.named_steps['clf'].predict(X_test_preprocessed)\n",
    "    \n",
    "#     # Calculate and print the accuracy\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     print(f\"Accuracy with {name}: {accuracy:.2f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
